,id,title,year,abstract,venues,url
0,126,syntopical graphs for computational argumentation tasks,2021,"approaches to computational argumentation tasks such as stance detection and aspect detection have largely focused on the text of independent claims, losing out on potentially valuable context provided by the rest of the collection. we introduce a general approach to these tasks motivated by syntopical reading, a reading process that emphasizes comparing and contrasting viewpoints in order to improve topic understanding. to capture collection-level context, we introduce the syntopical graph, a data structure for linking claims within a collection. a syntopical graph is a typed multi-graph where nodes represent claims and edges represent different possible pairwise relationships, such as entailment, paraphrase, or support. experiments applying syntopical graphs to the problems of detecting stance and aspects demonstrate state-of-the-art performance in each domain, significantly outperforming approaches that do not utilize collection-level information.","['ijcnlp-2021', 'acl-2021']",2021.acl-long.126.pdf
1,127,stance detection in covid-19 tweets,2021,"the prevalence of the covid-19 pandemic in day-to-day life has yielded large amounts of stance detection data on social media sites, as users turn to social media to share their views regarding various issues related to the pandemic, e.g. stay at home mandates and wearing face masks when out in public. we set out to make use of this data by collecting the stance expressed by twitter users, with respect to topics revolving around the pandemic. we annotate a new stance detection dataset, called covid-19-stance. using this newly annotated dataset, we train several established stance detection models to ascertain a baseline performance for this specific task. to further improve the performance, we employ self-training and domain adaptation approaches to take advantage of large amounts of unlabeled data and existing stance detection datasets. the dataset, code, and other resources are available on github.","['ijcnlp-2021', 'acl-2021']",2021.acl-long.127.pdf
2,128,topic-aware evidence reasoning and stance-aware aggregation for fact verification,2021,"fact verification is a challenging task that requires simultaneously reasoning and aggregating over multiple retrieved pieces of evidence to evaluate the truthfulness of a claim. existing approaches typically (i) explore the semantic interaction between the claim and evidence at different granularity levels but fail to capture their topical consistency during the reasoning process, which we believe is crucial for verification; (ii) aggregate multiple pieces of evidence equally without considering their implicit stances to the claim, thereby introducing spurious information. to alleviate the above issues, we propose a novel topic-aware evidence reasoning and stance-aware aggregation model for more accurate fact verification, with the following four key properties: 1) checking topical consistency between the claim and evidence; 2) maintaining topical coherence among multiple pieces of evidence; 3) ensuring semantic similarity between the global topic information and the semantic representation of evidence; 4) aggregating evidence based on their implicit stances to the claim. extensive experiments conducted on the two benchmark datasets demonstrate the superiority of the proposed model over several state-of-the-art approaches for fact verification. the source code can be obtained from https://github.com/jasenchn/tarsa.","['ijcnlp-2021', 'acl-2021']",2021.acl-long.128.pdf
3,1,advances in debating technologies: building ai that can debate humans,2021,"the tutorial focuses on debating technologies, a sub-field of computational argumentation defined as “computational technologies developed directly to enhance, support, and engage with human debating” (gurevych et al., 2016). a recent milestone in this field is project debater, which was revealed in 2019 as the first ai system that can debate human experts on complex topics. project debater is the third in the series of ibm research ai’s grand challenges, following deep blue and watson. it has been developed for over six years by a large team of researchers and engineers, and its live demonstration in february 2019 received massive media attention. this research effort has resulted in more than 50 scientific papers to date, and many datasets freely available for research purposes. we discuss the scientific challenges that arise when building such a system, including argument mining, argument quality assessment, stance classification, principled argument detection, narrative generation, and rebutting a human opponent. many of the underlying capabilities of project debater have been made freely available for academic research, and the tutorial will include a detailed explanation of how to use and leverage these tools. in addition to discussing individual components, the tutorial also provides a holistic view of a debating system. such a view is largely missing in the academic literature, where each paper typically addresses a specific problem in isolation. we present a complete pipeline of a debating system, and discuss the information flow and the interaction between the various components. finally, we discuss practical applications and future challenges of debating technologies.","['ijcnlp-2021', 'acl-2021']",2021.acl-tutorials.1.pdf
4,147,learning from revisions: quality assessment of claims in argumentation at scale,2021,"assessing the quality of arguments and of the claims the arguments are composed of has become a key task in computational argumentation. however, even if different claims share the same stance on the same topic, their assessment depends on the prior perception and weighting of the different aspects of the topic being discussed. this renders it difficult to learn topic-independent quality indicators. in this paper, we study claim quality assessment irrespective of discussed aspects by comparing different revisions of the same claim. we compile a large-scale corpus with over 377k claim revision pairs of various types from kialo.com, covering diverse topics from politics, ethics, entertainment, and others. we then propose two tasks: (a) assessing which claim of a revision pair is better, and (b) ranking all versions of a claim by quality. our first experiments with embedding-based logistic regression and transformer-based neural networks show promising results, suggesting that learned indicators generalize well across topics. in a detailed error analysis, we give insights into what quality dimensions of claims can be assessed reliably. we provide the data and scripts needed to reproduce all results.",['eacl-2021'],2021.eacl-main.147.pdf
5,184,a unified feature representation for lexical connotations,2021,"ideological attitudes and stance are often expressed through subtle meanings of words and phrases. understanding these connotations is critical to recognizing the cultural and emotional perspectives of the speaker. in this paper, we use distant labeling to create a new lexical resource representing connotation aspects for nouns and adjectives. our analysis shows that it aligns well with human judgments. additionally, we present a method for creating lexical representations that capture connotations within the embedding space and show that using the embeddings provides a statistically significant improvement on the task of stance detection when data is limited.",['eacl-2021'],2021.eacl-main.184.pdf
6,227,a few topical tweets are enough for effective user stance detection,2021,"user stance detection entails ascertaining the position of a user towards a target, such as an entity, topic, or claim. recent work that employs unsupervised classification has shown that performing stance detection on vocal twitter users, who have many tweets on a target, can be highly accurate (+98%). however, such methods perform poorly or fail completely for less vocal users, who may have authored only a few tweets about a target. in this paper, we tackle stance detection for such users using two approaches. in the first approach, we improve user-level stance detection by representing tweets using contextualized embeddings, which capture latent meanings of words in context. we show that this approach outperforms two strong baselines and achieves 89.6% accuracy and 91.3% macro f-measure on eight controversial topics. in the second approach, we expand the tweets of a given user using their twitter timeline tweets, which may not be topically relevant, and then we perform unsupervised classification of the user, which entails clustering a user with other users in the training set. this approach achieves 95.6% accuracy and 93.1% macro f-measure.",['eacl-2021'],2021.eacl-main.227.pdf
7,12,a dashboard for mitigating the covid-19 misinfodemic,2021,"this paper describes the current milestones achieved in our ongoing project that aims to understand the surveillance of, impact of and intervention on covid-19 misinfodemic on twitter. specifically, it introduces a public dashboard which, in addition to displaying case counts in an interactive map and a navigational panel, also provides some unique features not found in other places. particularly, the dashboard uses a curated catalog of covid-19 related facts and debunks of misinformation, and it displays the most prevalent information from the catalog among twitter users in user-selected u.s. geographic regions. the paper explains how to use bert models to match tweets with the facts and misinformation and to detect their stance towards such information. the paper also discusses the results of preliminary experiments on analyzing the spatio-temporal spread of misinformation.",['eacl-2021'],2021.eacl-demos.12.pdf
8,27,(mis)alignment between stance expressed in social media data and public opinion surveys,2021,"stance detection, which aims to determine whether an individual is for or against a target concept, promises to uncover public opinion from large streams of social media data. yet even human annotation of social media content does not always capture “stance” as measured by public opinion polls. we demonstrate this by directly comparing an individual’s self-reported stance to the stance inferred from their social media data. leveraging a longitudinal public opinion survey with respondent twitter handles, we conducted this comparison for 1,129 individuals across four salient targets. we find that recall is high for both “pro’’ and “anti’’ stance classifications but precision is variable in a number of cases. we identify three factors leading to the disconnect between text and author stance: temporal inconsistencies, differences in constructs, and measurement errors from both survey respondents and annotators. by presenting a framework for assessing the limitations of stance detection models, this work provides important insight into what stance detection truly measures.",['emnlp-2021'],2021.emnlp-main.27.pdf
9,290,"abstract, rationale, stance: a joint model for scientific claim verification",2021,"scientific claim verification can help the researchers to easily find the target scientific papers with the sentence evidence from a large corpus for the given claim. some existing works propose pipeline models on the three tasks of abstract retrieval, rationale selection and stance prediction. such works have the problems of error propagation among the modules in the pipeline and lack of sharing valuable information among modules. we thus propose an approach, named as arsjoint, that jointly learns the modules for the three tasks with a machine reading comprehension framework by including claim information. in addition, we enhance the information exchanges and constraints among tasks by proposing a regularization term between the sentence attention scores of abstract retrieval and the estimated outputs of rational selection. the experimental results on the benchmark dataset scifact show that our approach outperforms the existing works.",['emnlp-2021'],2021.emnlp-main.290.pdf
10,397,just say no: analyzing the stance of neural dialogue generation in offensive contexts,2021,"dialogue models trained on human conversations inadvertently learn to generate toxic responses. in addition to producing explicitly offensive utterances, these models can also implicitly insult a group or individual by aligning themselves with an offensive statement. to better understand the dynamics of contextually offensive language, we investigate the stance of dialogue model responses in offensive reddit conversations. specifically, we create toxichat, a crowd-annotated dataset of 2,000 reddit threads and model responses labeled with offensive language and stance. our analysis reveals that 42% of human responses agree with toxic comments, whereas only 13% agree with safe comments. this undesirable behavior is learned by neural dialogue models, such as dialogpt, which we show are two times more likely to agree with offensive comments. to enable automatic detection of offensive language, we fine-tuned transformer-based classifiers on toxichat that achieve 0.71 f1 for offensive labels and 0.53 macro-f1 for stance labels. finally, we quantify the effectiveness of controllable text generation (ctg) methods to mitigate the tendency of neural dialogue models to agree with offensive comments. compared to the baseline, our best ctg model achieves a 19% reduction in agreement with offensive comments and produces 29% fewer offensive replies. our work highlights the need for further efforts to characterize and analyze inappropriate behavior in dialogue models, in order to help make them safer.",['emnlp-2021'],2021.emnlp-main.397.pdf
11,450,human rationales as attribution priors for explainable stance detection,2021,"as nlp systems become better at detecting opinions and beliefs from text, it is important to ensure not only that models are accurate but also that they arrive at their predictions in ways that align with human reasoning. in this work, we present a method for imparting human-like rationalization to a stance detection model using crowdsourced annotations on a small fraction of the training data. we show that in a data-scarce setting, our approach can improve the reasoning of a state-of-the-art classifier—particularly for inputs containing challenging phenomena such as sarcasm—at no cost in predictive performance. furthermore, we demonstrate that attention weights surpass a leading attribution method in providing faithful explanations of our model’s predictions, thus serving as a computationally cheap and reliable source of attributions for our model.",['emnlp-2021'],2021.emnlp-main.450.pdf
12,511,improving stance detection with multi-dataset learning and knowledge distillation,2021,"stance detection determines whether the author of a text is in favor of, against or neutral to a specific target and provides valuable insights into important events such as legalization of abortion. despite significant progress on this task, one of the remaining challenges is the scarcity of annotations. besides, most previous works focused on a hard-label training in which meaningful similarities among categories are discarded during training. to address these challenges, first, we evaluate a multi-target and a multi-dataset training settings by training one model on each dataset and datasets of different domains, respectively. we show that models can learn more universal representations with respect to targets in these settings. second, we investigate the knowledge distillation in stance detection and observe that transferring knowledge from a teacher model to a student model can be beneficial in our proposed training settings. moreover, we propose an adaptive knowledge distillation (akd) method that applies instance-specific temperature scaling to the teacher and student predictions. results show that the multi-dataset model performs best on all datasets and it can be further improved by the proposed akd, outperforming the state-of-the-art by a large margin. we publicly release our code.",['emnlp-2021'],2021.emnlp-main.511.pdf
13,547,tribrid: stance classification with neural inconsistency detection,2021,"we study the problem of performing automatic stance classification on social media with neural architectures such as bert. although these architectures deliver impressive results, their level is not yet comparable to the one of humans and they might produce errors that have a significant impact on the downstream task (e.g., fact-checking). to improve the performance, we present a new neural architecture where the input also includes automatically generated negated perspectives over a given claim. the model is jointly learned to make simultaneously multiple predictions, which can be used either to improve the classification of the original perspective or to filter out doubtful predictions. in the first case, we propose a weakly supervised method for combining the predictions into a final one. in the second case, we show that using the confidence scores to remove doubtful predictions allows our method to achieve human-like performance over the retained information, which is still a sizable part of the original input.",['emnlp-2021'],2021.emnlp-main.547.pdf
14,609,explagraphs: an explanation graph generation task for structured commonsense reasoning,2021,"recent commonsense-reasoning tasks are typically discriminative in nature, where a model answers a multiple-choice question for a certain context. discriminative tasks are limiting because they fail to adequately evaluate the model’s ability to reason and explain predictions with underlying commonsense knowledge. they also allow such models to use reasoning shortcuts and not be “right for the right reasons”. in this work, we present explagraphs, a new generative and structured commonsense-reasoning task (and an associated dataset) of explanation graph generation for stance prediction. specifically, given a belief and an argument, a model has to predict if the argument supports or counters the belief and also generate a commonsense-augmented graph that serves as non-trivial, complete, and unambiguous explanation for the predicted stance. we collect explanation graphs through a novel create-verify-and-refine graph collection framework that improves the graph quality (up to 90%) via multiple rounds of verification and refinement. a significant 79% of our graphs contain external commonsense nodes with diverse structures and reasoning depths. next, we propose a multi-level evaluation framework, consisting of automatic metrics and human evaluation, that check for the structural and semantic correctness of the generated graphs and their degree of match with ground-truth graphs. finally, we present several structured, commonsense-augmented, and text generation models as strong starting points for this explanation graph generation task, and observe that there is a large gap with human performance, thereby encouraging future work for this new challenging task.",['emnlp-2021'],2021.emnlp-main.609.pdf
15,710,cross-domain label-adaptive stance detection,2021,"stance detection concerns the classification of a writer’s viewpoint towards a target. there are different task variants, e.g., stance of a tweet vs. a full article, or stance with respect to a claim vs. an (implicit) topic. moreover, task definitions vary, which includes the label inventory, the data collection, and the annotation protocol. all these aspects hinder cross-domain studies, as they require changes to standard domain adaptation approaches. in this paper, we perform an in-depth analysis of 16 stance detection datasets, and we explore the possibility for cross-domain learning from them. moreover, we propose an end-to-end unsupervised framework for out-of-domain prediction of unseen, user-defined labels. in particular, we combine domain adaptation techniques such as mixture of experts and domain-adversarial training with label embeddings, and we demonstrate sizable performance gains over strong baselines, both (i) in-domain, i.e., for seen targets, and (ii) out-of-domain, i.e., for unseen targets. finally, we perform an exhaustive analysis of the cross-domain results, and we highlight the important factors influencing the model performance.",['emnlp-2021'],2021.emnlp-main.710.pdf
16,795,on classifying whether two texts are on the same side of an argument,2021,"to ease the difficulty of argument stance classification, the task of same side stance classification (s3c) has been proposed. in contrast to actual stance classification, which requires a substantial amount of domain knowledge to identify whether an argument is in favor or against a certain issue, it is argued that, for s3c, only argument similarity within stances needs to be learned to successfully solve the task. we evaluate several transformer-based approaches on the dataset of the recent s3c shared task, followed by an in-depth evaluation and error analysis of our model and the task’s hypothesis. we show that, although we achieve state-of-the-art results, our model fails to generalize both within as well as across topics and domains when adjusting the sampling strategy of the training and test set to a more adversarial scenario. our evaluation shows that current state-of-the-art approaches cannot determine same side stance by considering only domain-independent linguistic similarity features, but appear to require domain knowledge and semantic inference, too.",['emnlp-2021'],2021.emnlp-main.795.pdf
17,204,a multi-task learning framework for multi-target stance detection,2021,none,"['ijcnlp-2021', 'acl-2021', 'findings-2021']",2021.findings-acl.204.pdf
18,208,p-stance: a large dataset for stance detection in political domain,2021,none,"['ijcnlp-2021', 'acl-2021', 'findings-2021']",2021.findings-acl.208.pdf
19,278,enhancing zero-shot and few-shot stance detection with commonsense knowledge graph,2021,none,"['ijcnlp-2021', 'acl-2021', 'findings-2021']",2021.findings-acl.278.pdf
20,253,melt: message-level transformer with masked document representations as pre-training for stance detection,2021,"much of natural language processing is focused on leveraging large capacity language models, typically trained over single messages with a task of predicting one or more tokens. however, modeling human language at higher-levels of context (i.e., sequences of messages) is under-explored. in stance detection and other social media tasks where the goal is to predict an attribute of a message, we have contextual data that is loosely semantically connected by authorship. here, we introduce message-level transformer (melt) – a hierarchical message-encoder pre-trained over twitter and applied to the task of stance prediction. we focus on stance prediction as a task benefiting from knowing the context of the message (i.e., the sequence of previous messages). the model is trained using a variant of masked-language modeling; where instead of predicting tokens, it seeks to generate an entire masked (aggregated) message vector via reconstruction loss. we find that applying this pre-trained masked message-level transformer to the downstream task of stance detection achieves f1 performance of 67%.","['emnlp-2021', 'findings-2021']",2021.findings-emnlp.253.pdf
21,34,aspect-controlled neural argument generation,2021,"we rely on arguments in our daily lives to deliver our opinions and base them on evidence, making them more convincing in turn. however, finding and formulating arguments can be challenging. in this work, we present the arg-ctrl - a language model for argument generation that can be controlled to generate sentence-level arguments for a given topic, stance, and aspect. we define argument aspect detection as a necessary method to allow this fine-granular control and crowdsource a dataset with 5,032 arguments annotated with aspects. our evaluation shows that the arg-ctrl is able to generate high-quality, aspect-specific arguments, applicable to automatic counter-argument generation. we publish the model weights and all datasets and code to train the arg-ctrl.",['naacl-2021'],2021.naacl-main.34.pdf
22,148,target-aware data augmentation for stance detection,2021,"the goal of stance detection is to identify whether the author of a text is in favor of, neutral or against a specific target. despite substantial progress on this task, one of the remaining challenges is the scarcity of annotations. data augmentation is commonly used to address annotation scarcity by generating more training samples. however, the augmented sentences that are generated by existing methods are either less diversified or inconsistent with the given target and stance label. in this paper, we formulate the data augmentation of stance detection as a conditional masked language modeling task and augment the dataset by predicting the masked word conditioned on both its context and the auxiliary sentence that contains target and label information. moreover, we propose another simple yet effective method that generates target-aware sentence by replacing a target mention with the other. experimental results show that our proposed methods significantly outperforms previous augmentation methods on 11 targets.",['naacl-2021'],2021.naacl-main.148.pdf
23,303,twt–wt: a dataset to assert the role of target entities for detecting stance of tweets,2021,"the stance detection task aims at detecting the stance of a tweet or a text for a target. these targets can be named entities or free-form sentences (claims). though the task involves reasoning of the tweet with respect to a target, we find that it is possible to achieve high accuracy on several publicly available twitter stance detection datasets without looking at the target sentence. specifically, a simple tweet classification model achieved human-level performance on the wt–wt dataset and more than two-third accuracy on various other datasets. we investigate the existence of biases in such datasets to find the potential spurious correlations of sentiment-stance relations and lexical choice associated with the stance category. furthermore, we propose a new large dataset free of such biases and demonstrate its aptness on the existing stance detection systems. our empirical findings show much scope for research on the stance detection task and proposes several considerations for creating future stance detection datasets.",['naacl-2021'],2021.naacl-main.303.pdf
24,376,knowledge enhanced masked language model for stance detection,2021,"detecting stance on twitter is especially challenging because of the short length of each tweet, the continuous coinage of new terminology and hashtags, and the deviation of sentence structure from standard prose. fine-tuned language models using large-scale in-domain data have been shown to be the new state-of-the-art for many nlp tasks, including stance detection. in this paper, we propose a novel bert-based fine-tuning method that enhances the masked language model for stance detection. instead of random token masking, we propose using a weighted log-odds-ratio to identify words with high stance distinguishability and then model an attention mechanism that focuses on these words. we show that our proposed approach outperforms the state of the art for stance detection on twitter data about the 2020 us presidential election.",['naacl-2021'],2021.naacl-main.376.pdf
25,379,adversarial learning for zero-shot stance detection on social media,2021,"stance detection on social media can help to identify and understand slanted news or commentary in everyday life. in this work, we propose a new model for zero-shot stance detection on twitter that uses adversarial learning to generalize across topics. our model achieves state-of-the-art performance on a number of unseen test topics with minimal computational costs. in addition, we extend zero-shot stance detection to topics not previously considered, highlighting future directions for zero-shot transfer.",['naacl-2021'],2021.naacl-main.379.pdf
26,387,multitask learning for emotionally analyzing sexual abuse disclosures,2021,"the #metoo movement on social media platforms initiated discussions over several facets of sexual harassment in our society. prior work by the nlp community for automated identification of the narratives related to sexual abuse disclosures barely explored this social phenomenon as an independent task. however, emotional attributes associated with textual conversations related to the #metoo social movement are complexly intertwined with such narratives. we formulate the task of identifying narratives related to the sexual abuse disclosures in online posts as a joint modeling task that leverages their emotional attributes through multitask learning. our results demonstrate that positive knowledge transfer via context-specific shared representations of a flexible cross-stitched parameter sharing model helps establish the inherent benefit of jointly modeling tasks related to sexual abuse disclosures with emotion classification from the text in homogeneous and heterogeneous settings. we show how for more domain-specific tasks related to sexual abuse disclosures such as sarcasm identification and dialogue act (refutation, justification, allegation) classification, homogeneous multitask learning is helpful, whereas for more general tasks such as stance and hate speech detection, heterogeneous multitask learning with emotion classification works better.",['naacl-2021'],2021.naacl-main.387.pdf
27,9,combining argumentation structure and language model for generating natural argumentative dialogue,2022,"argumentative dialogue is an important process where speakers discuss a specific theme for consensus building or decision making. in previous studies for generating consistent argumentative dialogue, retrieval-based methods with hand-crafted argumentation structures have been used. in this study, we propose a method to generate natural argumentative dialogues by combining an argumentation structure and language model. we trained the language model to rewrite a proposition of an argumentation structure on the basis of its information, such as keywords and stance, into the next utterance while considering its context, and we used the model to rewrite propositions in the argumentation structure. we manually evaluated the generated dialogues and found that the proposed method significantly improved the naturalness of dialogues without losing consistency of argumentation.","['aacl-2022', 'ijcnlp-2022']",2022.aacl-short.9.pdf
28,52,cofe: a new dataset of intra-multilingual multi-target stance classification from an online european participatory democracy platform,2022,"stance recognition over proposals is the task of automatically detecting whether a comment on a specific proposal is in favor of this proposal, against this proposal or that neither inference is likely. the dataset that we propose to use is an online debating platform inaugurated in 2021, where users can submit proposals and comment over proposals or over other comments. it contains 4.2k proposals and 20k comments focused on various topics. every comment and proposal can come written in another language, with more than 40% of the proposal/comment pairs containing at least two languages, creating a unique intra-multilingual setting. a portion of the data (more than 7k comment/proposal pairs, in 26 languages) was annotated by the writers with a self-tag assessing whether they are in favor or against the proposal. another part of the data (without self-tag) has been manually annotated: 1206 comments in 6 morphologically different languages (fr, de, en, el, it, hu) were tagged, leading to a krippendorff’s α of 0.69. this setting allows defining an intra-multilingual and multi-target stance classification task over online debates.","['aacl-2022', 'ijcnlp-2022']",2022.aacl-short.52.pdf
29,7,jointcl: a joint contrastive learning framework for zero-shot stance detection,2022,"zero-shot stance detection (zssd) aims to detect the stance for an unseen target during the inference stage. in this paper, we propose a joint contrastive learning (jointcl) framework, which consists of stance contrastive learning and target-aware prototypical graph contrastive learning. specifically, a stance contrastive learning strategy is employed to better generalize stance features for unseen targets. further, we build a prototypical graph for each instance to learn the target-based representation, in which the prototypes are deployed as a bridge to share the graph structures between the known targets and the unseen ones. then a novel target-aware prototypical graph contrastive learning strategy is devised to generalize the reasoning ability of target-based stance representations to the unseen targets. extensive experiments on three benchmark datasets show that the proposed approach achieves state-of-the-art performance in the zssd task.",['acl-2022'],2022.acl-long.7.pdf
30,162,iam: a comprehensive and large-scale dataset for integrated argument mining tasks,2022,"traditionally, a debate usually requires a manual preparation process, including reading plenty of articles, selecting the claims, identifying the stances of the claims, seeking the evidence for the claims, etc. as the ai debate attracts more attention these years, it is worth exploring the methods to automate the tedious process involved in the debating system. in this work, we introduce a comprehensive and large dataset named iam, which can be applied to a series of argument mining tasks, including claim extraction, stance classification, evidence extraction, etc. our dataset is collected from over 1k articles related to 123 topics. near 70k sentences in the dataset are fully annotated based on their argument properties (e.g., claims, stances, evidence, etc.). we further propose two new integrated argument mining tasks associated with the debate preparation process: (1) claim extraction with stance classification (cesc) and (2) claim-evidence pair extraction (cepe). we adopt a pipeline approach and an end-to-end method for each integrated task separately. promising experimental results are reported to show the values and challenges of our proposed tasks, and motivate future research on argument mining.",['acl-2022'],2022.acl-long.162.pdf
31,281,incorporating stock market signals for twitter stance detection,2022,"research in stance detection has so far focused on models which leverage purely textual input. in this paper, we investigate the integration of textual and financial signals for stance detection in the financial domain. specifically, we propose a robust multi-task neural architecture that combines textual input with high-frequency intra-day time series from stock market prices. moreover, we extend wt–wt, an existing stance detection dataset which collects tweets discussing mergers and acquisitions operations, with the relevant financial signal. importantly, the obtained dataset aligns with stander, an existing news stance detection dataset, thus resulting in a unique multimodal, multi-genre stance detection resource. we show experimentally and through detailed result analysis that our stance detection system benefits from financial information, and achieves state-of-the-art results on the wt–wt dataset: this demonstrates that the combination of multiple input signals is effective for cross-target stance detection, and opens interesting research directions for future work.",['acl-2022'],2022.acl-long.281.pdf
32,35,towards fine-grained classification of climate change related social media text,2022,"with climate change becoming a cause of concern worldwide, it becomes essential to gauge people’s reactions. this can help educate and spread awareness about it and help leaders improve decision-making. this work explores the fine-grained classification and stance detection of climate change-related social media text. firstly, we create two datasets, climatestance and climateeng, consisting of 3777 tweets each, posted during the 2019 united nations framework convention on climate change and comprehensively outline the dataset collection, annotation methodology, and dataset composition. secondly, we propose the task of climate change stance detection based on our proposed climatestance dataset. thirdly, we propose a fine-grained classification based on the climateeng dataset, classifying social media text into five categories: disaster, ocean/water, agriculture/forestry, politics, and general. we benchmark both the datasets for climate change stance detection and fine-grained classification using state-of-the-art methods in text classification. we also create a reddit-based dataset for both the tasks, climatereddit, consisting of 6262 pseudo-labeled comments along with 329 manually annotated comments for the label. we then perform semi-supervised experiments for both the tasks and benchmark their results using the best-performing model for the supervised experiments. lastly, we provide insights into the climatestance and climatereddit using part-of-speech tagging and named-entity recognition.",['acl-2022'],2022.acl-srw.35.pdf
33,48,基于主题提示学习的零样本立场检测方法(a topic-based prompt learning method for zero-shot stance detection),2022,"“零样本立场检测目的是针对未知目标数据进行立场极性预测。一般而言,文本的立场表达是与所讨论的目标主题是紧密联系的。针对未知目标的立场检测,本文将立场表达划分为两种类型:一类在说话者面向不同的主题和讨论目标时表达相同的立场态度,称之为目标无关的表达;另一类在说话者面向特定主题和讨论目标时才表达相应的立场态度,本文称之为目标依赖的表达。对这两种表达进行区分,有效学习到目标无关的表达方式并忽略目标依赖的表达方式,有望强化模型的可迁移能力,使其更加适应零样本立场检测任务。据此,本文提出了一种基于主题提示学习的零样本立场检测方法。具体而言,受自监督学习的启发,本文为了零样本立场检测设置了一个代理任务框架。其中,代理任务通过掩盖上下文中的目标主题词生成辅助样本,并基于提示学习分别预测原样本和辅助样本的立场表达,随后判断原样本和辅助样本的立场表达是否一致,从而在无需人工标注的情况下判断样本的立场表达是否依赖于目标的代理标签。然后,将此代理标签提供给立场检测模型,对应学习可迁移的立场检测特征。在两个基准数据集上的大量实验表明,本文提出的方法在零样本立场检测任务中相比基线模型取得了更优的性能。”",['ccl-2022'],2022.ccl-1.48.pdf
34,345,singlish message paraphrasing: a joint task of creole translation and text normalization,2022,"within the natural language processing community, english is by far the most resource-rich language. there is emerging interest in conducting translation via computational approaches to conform its dialects or creole languages back to standard english. this computational approach paves the way to leverage generic english language backbones, which are beneficial for various downstream tasks. however, in practical online communication scenarios, the use of language varieties is often accompanied by noisy user-generated content, making this translation task more challenging. in this work, we introduce a joint paraphrasing task of creole translation and text normalization of singlish messages, which can shed light on how to process other language varieties and dialects. we formulate the task in three different linguistic dimensions: lexical level normalization, syntactic level editing, and semantic level rewriting. we build an annotated dataset of singlish-to-standard english messages, and report performance on a perturbation-resilient sequence-to-sequence model. experimental results show that the model produces reasonable generation results, and can improve the performance of downstream tasks like stance detection.",['coling-2022'],2022.coling-1.345.pdf
35,347,"one word, two sides: traces of stance in contextualized word representations",2022,"the way we use words is influenced by our opinion. we investigate whether this is reflected in contextualized word embeddings. for example, is the representation of “animal” different between people who would abolish zoos and those who would not? we explore this question from a lexical semantic change standpoint. our experiments with bert embeddings derived from datasets with stance annotations reveal small but significant differences in word representations between opposing stances.",['coling-2022'],2022.coling-1.347.pdf
36,596,ssr: utilizing simplified stance reasoning process for robust stance detection,2022,"dataset bias in stance detection tasks allows models to achieve superior performance without using targets. most existing debiasing methods are task-agnostic, which fail to utilize task knowledge to better discriminate between genuine and bias features. motivated by how humans tackle stance detection tasks, we propose to incorporate the stance reasoning process as task knowledge to assist in learning genuine features and reducing reliance on bias features. the full stance reasoning process usually involves identifying the span of the mentioned target and corresponding opinion expressions, such fine-grained annotations are hard and expensive to obtain. to alleviate this, we simplify the stance reasoning process to relax the granularity of annotations from token-level to sentence-level, where labels for sub-tasks can be easily inferred from existing resources. we further implement those sub-tasks by maximizing mutual information between the texts and the opinioned targets. to evaluate whether stance detection models truly understand the task from various aspects, we collect and construct a series of new test sets. our proposed model achieves better performance than previous task-agnostic debiasing methods on most of those new test sets while maintaining comparable performances to existing stance detection models.",['coling-2022'],2022.coling-1.596.pdf
37,605,target really matters: target-aware contrastive learning and consistency regularization for few-shot stance detection,2022,"stance detection aims to identify the attitude from an opinion towards a certain target. despite the significant progress on this task, it is extremely time-consuming and budget-unfriendly to collect sufficient high-quality labeled data for every new target under fully-supervised learning, whereas unlabeled data can be collected easier. therefore, this paper is devoted to few-shot stance detection and investigating how to achieve satisfactory results in semi-supervised settings. as a target-oriented task, the core idea of semi-supervised few-shot stance detection is to make better use of target-relevant information from labeled and unlabeled data. therefore, we develop a novel target-aware semi-supervised framework. specifically, we propose a target-aware contrastive learning objective to learn more distinguishable representations for different targets. such an objective can be easily applied with or without unlabeled data. furthermore, to thoroughly exploit the unlabeled data and facilitate the model to learn target-relevant stance features in the opinion content, we explore a simple but effective target-aware consistency regularization combined with a self-training strategy. the experimental results demonstrate that our approach can achieve state-of-the-art performance on multiple benchmark datasets in the few-shot setting.",['coling-2022'],2022.coling-1.605.pdf
38,621,exploiting sentiment and common sense for zero-shot stance detection,2022,"the stance detection task aims to classify the stance toward given documents and topics. since the topics can be implicit in documents and unseen in training data for zero-shot settings, we propose to boost the transferability of the stance detection model by using sentiment and commonsense knowledge, which are seldom considered in previous studies. our model includes a graph autoencoder module to obtain commonsense knowledge and a stance detection module with sentiment and commonsense. experimental results show that our model outperforms the state-of-the-art methods on the zero-shot and few-shot benchmark dataset–vast. meanwhile, ablation studies prove the significance of each module in our model. analysis of the relations between sentiment, common sense, and stance indicates the effectiveness of sentiment and common sense.",['coling-2022'],2022.coling-1.621.pdf
39,138,stanceosaurus: classifying stance towards multicultural misinformation,2022,"we present stanceosaurus, a new corpus of 28,033 tweets in english, hindi and arabic annotated with stance towards 250 misinformation claims. as far as we are aware, it is the largest corpus annotated with stance towards misinformation claims. the claims in stanceosaurus originate from 15 fact-checking sources that cover diverse geographical regions and cultures. unlike existing stance datasets, we introduce a more fine-grained 5-class labeling strategy with additional subcategories to distinguish implicit stance. pre-trained transformer-based stance classifiers that are fine-tuned on our corpus show good generalization on unseen claims and regional claims from countries outside the training data. cross-lingual experiments demonstrate stanceosaurus’ capability of training multilingual models, achieving 53.1 f1 on hindi and 50.4 f1 on arabic without any target-language fine-tuning. finally, we show how a domain adaptation method can be used to improve performance on stanceosaurus using additional rumoureval-2019 data. we will make stanceosaurus publicly available to the research community upon publication and hope it will encourage further work on misinformation identification across languages and cultures.",['emnlp-2022'],2022.emnlp-main.138.pdf
40,193,improving multi-task stance detection with multi-task interaction network,2022,"stance detection aims to identify people’s standpoints expressed in the text towards a target, which can provide powerful information for various downstream tasks.recent studies have proposed multi-task learning models that introduce sentiment information to boost stance detection.however, they neglect to explore capturing the fine-grained task-specific interaction between stance detection and sentiment tasks, thus degrading performance.to address this issue, this paper proposes a novel multi-task interaction network (mtin) for improving the performance of stance detection and sentiment analysis tasks simultaneously.specifically, we construct heterogeneous task-related graphs to automatically identify and adapt the roles that a word plays with respect to a specific task. also, a multi-task interaction module is designed to capture the word-level interaction between tasks, so as to obtain richer task representations.extensive experiments on two real-world datasets show that our proposed approach outperforms state-of-the-art methods in both stance detection and sentiment analysis tasks.",['emnlp-2022'],2022.emnlp-main.193.pdf
41,470,generative data augmentation with contrastive learning for zero-shot stance detection,2022,"stance detection aims to identify whether the author of an opinionated text is in favor of, against, or neutral towards a given target. remarkable success has been achieved when sufficient labeled training data is available. however, it is labor-intensive to annotate sufficient data and train the model for every new target.therefore, zero-shot stance detection, aiming at identifying stances of unseen targets with seen targets, has gradually attracted attention. among them, one of the important challenges is to reduce the domain transfer between seen and unseen targets. to tackle this problem, we propose a generative data augmentation approach to generate training samples containing targets and stances for testing data, and map the real samples and generated synthetic samples into the same embedding space with contrastive learning, then perform the final classification based on the augmented data. we evaluate our proposed model on two benchmark datasets. experimental results show that our approach achieves state-of-the-art performance on most topics in the task of zero-shot stance detection.",['emnlp-2022'],2022.emnlp-main.470.pdf
42,676,generative entity-to-entity stance detection with knowledge graph augmentation,2022,"stance detection is typically framed as predicting the sentiment in a given text towards a target entity. however, this setup overlooks the importance of the source entity, i.e., who is expressing the opinion. in this paper, we emphasize the imperative need for studying interactions among entities when inferring stances. we first introduce a new task, entity-to-entity (e2e) stance detection, which primes models to identify entities in their canonical names and discern stances jointly. to support this study, we curate a new dataset with 10,641 annotations labeled at the sentence level from news articles of different ideological leanings. we present a novel generative framework to allow the generation of canonical names for entities as well as stances among them. we further enhance the model with a graph encoder to summarize entity activities and external knowledge surrounding the entities. experiments show that our model outperforms strong comparisons by large margins. further analyses demonstrate the usefulness of e2e stance detection for understanding media quotation and stance landscape as well as inferring entity ideology.",['emnlp-2022'],2022.emnlp-main.676.pdf
43,824,par: political actor representation learning with social context and expert knowledge,2022,"modeling the ideological perspectives of political actors is an essential task in computational political science with applications in many downstream tasks. existing approaches are generally limited to textual data and voting records, while they neglect the rich social context and valuable expert knowledge for holistic ideological analysis. in this paper, we propose par, a political actor representation learning framework that jointly leverages social context and expert knowledge. specifically, we retrieve and extract factual statements about legislators to leverage social context information. we then construct a heterogeneous information network to incorporate social context and use relational graph neural networks to learn legislator representations. finally, we train par with three objectives to align representation learning with expert knowledge, model ideological stance consistency, and simulate the echo chamber phenomenon. extensive experiments demonstrate that par is better at augmenting political text understanding and successfully advances the state-of-the-art in political perspective detection and roll call vote prediction. further analysis proves that par learns representations that reflect the political reality and provide new insights into political behavior.",['emnlp-2022'],2022.emnlp-main.824.pdf
44,264,from stance to concern: adaptation of propositional analysis to new tasks and domains,2022,"we present a generalized paradigm for adaptation of propositional analysis (predicate-argument pairs) to new tasks and domains. we leverage an analogy between stances (belief-driven sentiment) and concerns (topical issues with moral dimensions/endorsements) to produce an explanatory representation. a key contribution is the combination of semi-automatic resource building for extraction of domain-dependent concern types (with 2-4 hours of human labor per domain) and an entirely automatic procedure for extraction of domain-independent moral dimensions and endorsement values. prudent (automatic) selection of terms from propositional structures for lexical expansion (via semantic similarity) produces new moral dimension lexicons at three levels of granularity beyond a strong baseline lexicon. we develop a ground truth (gt) based on expert annotators and compare our concern detection output to gt, to yield 231% improvement in recall over baseline, with only a 10% loss in precision. f1 yields 66% improvement over baseline and 97.8% of human performance. our lexically based approach yields large savings over approaches that employ costly human labor and model building. we provide to the community a newly expanded moral dimension/value lexicon, annotation guidelines, and gt.","['acl-2022', 'findings-2022']",2022.findings-acl.264.pdf
45,94,a survey on stance detection for mis- and disinformation identification,2022,"understanding attitudes expressed in texts, also known as stance detection, plays an important role in systems for detecting false information online, be it misinformation (unintentionally false) or disinformation (intentionally false information). stance detection has been framed in different ways, including (a) as a component of fact-checking, rumour detection, and detecting previously fact-checked claims, or (b) as a task in its own right. while there have been prior efforts to contrast stance detection with other related tasks such as argumentation mining and sentiment analysis, there is no existing survey on examining the relationship between stance detection and mis- and disinformation detection. here, we aim to bridge this gap by reviewing and analysing existing work in this area, with mis- and disinformation in focus, and discussing lessons learnt and future challenges.","['findings-2022', 'naacl-2022']",2022.findings-naacl.94.pdf
46,101,politics: pretraining with same-story article comparison for ideology prediction and stance detection,2022,"ideology is at the core of political science research. yet, there still does not exist general-purpose tools to characterize and predict ideology across different genres of text. to this end, we study pretrained language models using novel ideology-driven pretraining objectives that rely on the comparison of articles on the same story written by media of different ideologies. we further collect a large-scale dataset, consisting of more than 3.6m political news articles, for pretraining. our model politics outperforms strong baselines and the previous state-of-the-art models on ideology prediction and stance detection tasks. further analyses show that politics is especially good at understanding long or formally written texts, and is also robust in few-shot learning scenarios.","['findings-2022', 'naacl-2022']",2022.findings-naacl.101.pdf
47,39,differential bias: on the perceptibility of stance imbalance in argumentation,2022,"most research on natural language processing treats bias as an absolute concept: based on a (probably complex) algorithmic analysis, a sentence, an article, or a text is classified as biased or not. given the fact that for humans the question of whether a text is biased can be difficult to answer or is answered contradictory, we ask whether an “absolute bias classification” is a promising goal at all. we see the problem not in the complexity of interpreting language phenomena but in the diversity of sociocultural backgrounds of the readers, which cannot be handled uniformly: to decide whether a text has crossed the proverbial line between non-biased and biased is subjective. by asking “is text x more [less, equally] biased than text y?” we propose to analyze a simpler problem, which, by its construction, is rather independent of standpoints, views, or sociocultural aspects. in such a model, bias becomes a preference relation that induces a partial ordering from least biased to most biased texts without requiring a decision on where to draw the line. a prerequisite for this kind of bias model is the ability of humans to perceive relative bias differences in the first place. in our research, we selected a specific type of bias in argumentation, the stance bias, and designed a crowdsourcing study showing that differences in stance bias are perceptible when (light) support is provided through training or visual aid.","['aacl-2022', 'findings-2022']",2022.findings-aacl.39.pdf
48,83,knowledge stimulated contrastive prompting for low-resource stance detection,2022,"stance detection task (sdt) aims at identifying the stance of the sentence towards a specific target and is usually modeled as a classification problem. backgound knowledge is often necessary for stance detection with respect to a specific target, especially when there is no target explicitly mentioned in text. this paper focuses on the knowledge stimulation for low-resource stance detection tasks. we firstly explore to formalize stance detection as a prompt based contrastive learning task. at the same time, to make prompt learning suit to stance detection, we design a template mechanism to incorporate corresponding target into instance representation. furthermore, we propose a masked language prompt joint contrastive learning approach to stimulate the knowledge inherit from the pre-trained model. the experimental results on three benchmarks show that knowledge stimulation is effective in stance detection accompanied with our proposed mechanism.","['findings-2022', 'emnlp-2022']",2022.findings-emnlp.83.pdf
49,151,assisting the human fact-checkers: detecting all previously fact-checked claims in a document,2022,"given the recent proliferation of false claims online, there has been a lot of manual fact-checking effort. as this is very time-consuming, human fact-checkers can benefit from tools that can support them and make them more efficient. here, we focus on building a system that could provide such support. given an input document, it aims to detect all sentences that contain a claim that can be verified by some previously fact-checked claims (from a given database). the output is a re-ranked list of the document sentences, so that those that can be verified are ranked as high as possible, together with corresponding evidence. unlike previous work, which has looked into claim retrieval, here we take a document-level perspective. we create a new manually annotated dataset for the task, and we propose suitable evaluation measures. we further experiment with a learning-to-rank approach, achieving sizable performance gains over several strong baselines. our analysis demonstrates the importance of modeling text similarity and stance, while also taking into account the veracity of the retrieved previously fact-checked claims. we believe that this research would be of interest to fact-checkers, journalists, media, and regulatory authorities.","['findings-2022', 'emnlp-2022']",2022.findings-emnlp.151.pdf
50,294,you are what you talk about: inducing evaluative topics for personality analysis,2022,"expressing attitude or stance toward entities and concepts is an integral part of human behavior and personality. recently, evaluative language data has become more accessible with social media’s rapid growth, enabling large-scale opinion analysis. however, surprisingly little research examines the relationship between personality and evaluative language. to bridge this gap, we introduce the notion of evaluative topics, obtained by applying topic models to pre-filtered evaluative text from social media. we then link evaluative topics to individual text authors to build their evaluative profiles. we apply evaluative profiling to reddit comments labeled with personality scores and conduct an exploratory study on the relationship between evaluative topics and big five personality facets, aiming for a more interpretable, facet-level analysis. finally, we validate our approach by observing correlations consistent with prior research in personality psychology.","['findings-2022', 'emnlp-2022']",2022.findings-emnlp.294.pdf
51,335,opening up minds with argumentative dialogues,2022,"recent research on argumentative dialogues has focused on persuading people to take some action, changing their stance on the topic of discussion, or winning debates. in this work, we focus on argumentative dialogues that aim to open up (rather than change) people’s minds to help them become more understanding to views that are unfamiliar or in opposition to their own convictions. to this end, we present a dataset of 183 argumentative dialogues about 3 controversial topics: veganism, brexit and covid-19 vaccination. the dialogues were collected using the wizard of oz approach, where wizards leverage a knowledge-base of arguments to converse with participants. open-mindedness is measured before and after engaging in the dialogue using a questionnaire from the psychology literature, and success of the dialogue is measured as the change in the participant’s stance towards those who hold opinions different to theirs. we evaluate two dialogue models: a wikipedia-based and an argument-based model. we show that while both models perform closely in terms of opening up minds, the argument-based model is significantly better on other dialogue properties such as engagement and clarity.","['findings-2022', 'emnlp-2022']",2022.findings-emnlp.335.pdf
52,406,language model detoxification in dialogue with contextualized stance control,2022,"to reduce the toxic degeneration in a pretrained language model (lm), previous work on language model detoxification has focused on reducing the toxicity of the generation itself (self-toxicity) without consideration of the context. as a result, a type of implicit offensive language where the generations support the offensive language in the context is ignored. different from the lm controlling tasks in previous work, where the desired attributes are fixed for generation, the desired stance of the generation depends on the offensiveness of the context. therefore, we propose a novel control method to do context-dependent detoxification with the stance taken into consideration. we introduce meta prefixes to learn the contextualized stance control strategy and to generate the stance control prefix according to the input context. the generated stance prefix is then combined with the toxicity control prefix to guide the response generation. experimental results show that our proposed method can effectively learn the context-dependent stance control strategies while keeping a low self-toxicity of the underlying lm.","['findings-2022', 'emnlp-2022']",2022.findings-emnlp.406.pdf
53,259,extracting and analysing metaphors in migration media discourse: towards a metaphor annotation scheme,2022,"the study of metaphors in media discourse is an increasingly researched topic as media are an important shaper of social reality and metaphors are an indicator of how we think about certain issues through references to other things. we present a neural transfer learning method for detecting metaphorical sentences in slovene and evaluate its performance on a gold standard corpus of metaphors (classification accuracy of 0.725), as well as on a sample of a domain specific corpus of migrations (precision of 0.40 for extracting domain metaphors and 0.74 if evaluated only on a set of migration related sentences). based on empirical results and findings of our analysis, we propose a novel metaphor annotation scheme containing linguistic level, conceptual level, and stance information. the new scheme can be used for future metaphor annotations of other socially relevant topics.",['lrec-2022'],2022.lrec-1.259.pdf
54,261,lpattack: a feasible annotation scheme for capturing logic pattern of attacks in arguments,2022,"in argumentative discourse, persuasion is often achieved by refuting or attacking others’ arguments. attacking an argument is not always straightforward and often consists of complex rhetorical moves in which arguers may agree with a logic of an argument while attacking another logic. furthermore, an arguer may neither deny nor agree with any logics of an argument, instead ignore them and attack the main stance of the argument by providing new logics and presupposing that the new logics have more value or importance than the logics presented in the attacked argument. however, there are no studies in computational argumentation that capture such complex rhetorical moves in attacks or the presuppositions or value judgments in them. to address this gap, we introduce lpattack, a novel annotation scheme that captures the common modes and complex rhetorical moves in attacks along with the implicit presuppositions and value judgments. our annotation study shows moderate inter-annotator agreement, indicating that human annotation for the proposed scheme is feasible. we publicly release our annotated corpus and the annotation guidelines.",['lrec-2022'],2022.lrec-1.261.pdf
55,293,iso-based annotated multilingual parallel corpus for discourse markers,2022,"discourse markers carry information about the discourse structure and organization, and also signal local dependencies or epistemological stance of speaker. they provide instructions on how to interpret the discourse, and their study is paramount to understand the mechanism underlying discourse organization. this paper presents a new language resource, an iso-based annotated multilingual parallel corpus for discourse markers. the corpus comprises nine languages, bulgarian, lithuanian, german, european portuguese, hebrew, romanian, polish, and macedonian, with english as a pivot language. in order to represent the meaning of the discourse markers, we propose an annotation scheme of discourse relations from iso 24617-8 with a plug-in to iso 24617-2 for communicative functions. we describe an experiment in which we applied the annotation scheme to assess its validity. the results reveal that, although some extensions are required to cover all the multilingual data, it provides a proper representation of discourse markers value. additionally, we report some relevant contrastive phenomena concerning discourse markers interpretation and role in discourse. this first step will allow us to develop deep learning methods to identify and extract discourse relations and communicative functions, and to represent that information as linguistic linked open data (llod).",['lrec-2022'],2022.lrec-1.293.pdf
56,344,arcovidvac: analyzing arabic tweets about covid-19 vaccination,2022,"the emergence of the covid-19 pandemic and the first global infodemic have changed our lives in many different ways. we relied on social media to get the latest information about covid-19 pandemic and at the same time to disseminate information. the content in social media consisted not only health related advice, plans, and informative news from policymakers, but also contains conspiracies and rumors. it became important to identify such information as soon as they are posted to make an actionable decision (e.g., debunking rumors, or taking certain measures for traveling). to address this challenge, we develop and publicly release the first largest manually annotated arabic tweet dataset, arcovidvac, for covid-19 vaccination campaign, covering many countries in the arab region. the dataset is enriched with different layers of annotation, including, (i) informativeness more vs. less importance of the tweets); (ii) fine-grained tweet content types (e.g., advice, rumors, restriction, authenticate news/information); and (iii) stance towards vaccination (pro-vaccination, neutral, anti-vaccination). further, we performed in-depth analysis of the data, exploring the popularity of different vaccines, trending hashtags, topics, and presence of offensiveness in the tweets. we studied the data for individual types of tweets and temporal changes in stance towards vaccine. we benchmarked the arcovidvac dataset using transformer architectures for informativeness, content types, and stance detection.",['lrec-2022'],2022.lrec-1.344.pdf
57,405,investigating user radicalization: a novel dataset for identifying fine-grained temporal shifts in opinion,2022,"there is an increasing need for the ability to model fine-grained opinion shifts of social media users, as concerns about the potential polarizing social effects increase. however, the lack of publicly available datasets that are suitable for the task presents a major challenge. in this paper, we introduce an innovative annotated dataset for modeling subtle opinion fluctuations and detecting fine-grained stances. the dataset includes a sufficient amount of stance polarity and intensity labels per user over time and within entire conversational threads, thus making subtle opinion fluctuations detectable both in long term and in short term. all posts are annotated by non-experts and a significant portion of the data is also annotated by experts. we provide a strategy for recruiting suitable non-experts. our analysis of the inter-annotator agreements shows that the resulting annotations obtained from the majority vote of the non-experts are of comparable quality to the annotations of the experts. we provide analyses of the stance evolution in short term and long term levels, a comparison of language usage between users with vacillating and resolute attitudes, and fine-grained stance detection baselines.",['lrec-2022'],2022.lrec-1.405.pdf
58,753,vaccinelies: a natural language resource for learning to recognize misinformation about the covid-19 and hpv vaccines,2022,"billions of covid-19 vaccines have been administered, but many remain hesitant. misinformation about the covid-19 vaccines and other vaccines, propagating on social media, is believed to drive hesitancy towards vaccination. the ability to automatically recognize misinformation targeting vaccines on twitter depends on the availability of data resources. in this paper we present vaccinelies, a large collection of tweets propagating misinformation about two vaccines: the covid-19 vaccines and the human papillomavirus (hpv) vaccines. misinformation targets are organized in vaccine-specific taxonomies, which reveal the misinformation themes and concerns. the ontological commitments of the misinformation taxonomies provide an understanding of which misinformation themes and concerns dominate the discourse about the two vaccines covered in vaccinelies. the organization into training, testing and development sets of vaccinelies invites the development of novel supervised methods for detecting misinformation on twitter and identifying the stance towards it. furthermore, vaccinelies can be a stepping stone for the development of datasets focusing on misinformation targeting additional vaccines.",['lrec-2022'],2022.lrec-1.753.pdf
59,783,using convolution neural network with bert for stance detection in vietnamese,2022,"stance detection is the task of automatically eliciting stance information towards a specific claim made by a primary author. while most studies have been done for high-resource languages, this work is dedicated to a low-resource language, namely vietnamese. in this paper, we propose an architecture using transformers to detect stances in vietnamese claims. this architecture exploits bert to extract contextual word embeddings instead of using traditional word2vec models. then, these embeddings are fed into cnn networks to extract local features to train the stance detection model. we performed extensive comparison experiments to show the effectiveness of the proposed method on a public dataset1 experimental results show that this proposed model outperforms the previous methods by a large margin. it yielded an accuracy score of 75.57% averaged on four labels. this sets a new sota result for future research on this interesting problem in vietnamese.",['lrec-2022'],2022.lrec-1.783.pdf
60,801,polibertweet: a pre-trained language model for analyzing political content on twitter,2022,"transformer-based models have become the state-of-the-art for numerous natural language processing (nlp) tasks, especially for noisy data sets, including social media posts. for example, bertweet, pre-trained roberta on a large amount of twitter data, has achieved state-of-the-art results on several twitter nlp tasks. we argue that it is not only important to have general pre-trained models for a social media platform, but also domain-specific ones that better capture domain-specific language context. domain-specific resources are not only important for nlp tasks associated with a specific domain, but they are also useful for understanding language differences across domains. one domain that receives a large amount of attention is politics, more specifically political elections. towards that end, we release polibertweet, a pre-trained language model trained from bertweet on over 83m us 2020 election-related english tweets. while the construction of the resource is fairly straightforward, we believe that it can be used for many important downstream tasks involving language, including political misinformation analysis and election public opinion analysis. to show the value of this resource, we evaluate polibertweet on different nlp tasks. the results show that our model outperforms general-purpose language models in domain-specific contexts, highlighting the value of domain-specific models for more detailed linguistic analysis. we also extend other existing language models with a sample of these data and show their value for presidential candidate stance detection, a context-specific task. we release polibertweet and these other models to the community to advance interdisciplinary research related to election 2020.",['lrec-2022'],2022.lrec-1.801.pdf
61,17,political ideology and polarization: a multi-dimensional approach,2022,"analyzing ideology and polarization is of critical importance in advancing our grasp of modern politics. recent research has made great strides towards understanding the ideological bias (i.e., stance) of news media along the left-right spectrum. in this work, we instead take a novel and more nuanced approach for the study of ideology based on its left or right positions on the issue being discussed. aligned with the theoretical accounts in political science, we treat ideology as a multi-dimensional construct, and introduce the first diachronic dataset of news articles whose ideological positions are annotated by trained political scientists and linguists at the paragraph level. we showcase that, by controlling for the author’s stance, our method allows for the quantitative and temporal measurement and analysis of polarization as a multidimensional ideological distance. we further present baseline models for ideology prediction, outlining a challenging task distinct from stance detection.",['naacl-2022'],2022.naacl-main.17.pdf
62,89,disapere: a dataset for discourse structure in peer review discussions,2022,"at the foundation of scientific evaluation is the labor-intensive process of peer review. this critical task requires participants to consume vast amounts of highly technical text. prior work has annotated different aspects of review argumentation, but discourse relations between reviews and rebuttals have yet to be examined. we present disapere, a labeled dataset of 20k sentences contained in 506 review-rebuttal pairs in english, annotated by experts. disapere synthesizes label sets from prior work and extends them to include fine-grained annotation of the rebuttal sentences, characterizing their context in the review and the authors’ stance towards review arguments. further, we annotate every review and rebuttal sentence. we show that discourse cues from rebuttals can shed light on the quality and interpretation of reviews. further, an understanding of the argumentative strategies employed by the reviewers and authors provides useful signal for area chairs and other decision makers.",['naacl-2022'],2022.naacl-main.89.pdf
63,112,disentangled learning of stance and aspect topics for vaccine attitude detection in social media,2022,"building models to detect vaccine attitudes on social media is challenging because of the composite, often intricate aspects involved, and the limited availability of annotated data. existing approaches have relied heavily on supervised training that requires abundant annotations and pre-defined aspect categories. instead, with the aim of leveraging the large amount of unannotated data now available on vaccination, we propose a novel semi-supervised approach for vaccine attitude detection, called vadet. a variational autoencoding architecture based on language models is employed to learn from unlabelled data the topical information of the domain. then, the model is fine-tuned with a few manually annotated examples of user attitudes. we validate the effectiveness of vadet on our annotated data and also on an existing vaccination corpus annotated with opinions on vaccines. our results show that vadet is able to learn disentangled stance and aspect topics, and outperforms existing aspect-based sentiment analysis models on both stance detection and tweet clustering.",['naacl-2022'],2022.naacl-main.112.pdf
64,427,a holistic framework for analyzing the covid-19 vaccine debate,2022,"the covid-19 pandemic has led to infodemic of low quality information leading to poor health decisions. combating the outcomes of this infodemic is not only a question of identifying false claims, but also reasoning about the decisions individuals make. in this work we propose a holistic analysis framework connecting stance and reason analysis, and fine-grained entity level moral sentiment analysis. we study how to model the dependencies between the different level of analysis and incorporate human insights into the learning process. experiments show that our framework provides reliable predictions even in the low-supervision settings.",['naacl-2022'],2022.naacl-main.427.pdf
65,220,guiding computational stance detection with expanded stance triangle framework,2023,"stance detection determines whether the author of a piece of text is in favor of, against, or neutral towards a specified target, and can be used to gain valuable insights into social media. the ubiquitous indirect referral of targets makes this task challenging, as it requires computational solutions to model semantic features and infer the corresponding implications from a literal statement. moreover, the limited amount of available training data leads to subpar performance in out-of-domain and cross-target scenarios, as data-driven approaches are prone to rely on superficial and domain-specific features. in this work, we decompose the stance detection task from a linguistic perspective, and investigate key components and inference paths in this task. the stance triangle is a generic linguistic framework previously proposed to describe the fundamental ways people express their stance. we further expand it by characterizing the relationship between explicit and implicit objects. we then use the framework to extend one single training corpus with additional annotation. experimental results show that strategically-enriched data can significantly improve the performance on out-of-domain and cross-target evaluation.",['acl-2023'],2023.acl-long.220.pdf
66,368,"trillion dollar words: a new financial dataset, task & market analysis",2023,"monetary policy pronouncements by federal open market committee (fomc) are a major driver of financial market returns. we construct the largest tokenized and annotated dataset of fomc speeches, meeting minutes, and press conference transcripts in order to understand how monetary policy influences financial markets. in this study, we develop a novel task of hawkish-dovish classification and benchmark various pre-trained language models on the proposed dataset. using the best-performing model (roberta-large), we construct a measure of monetary policy stance for the fomc document release days. to evaluate the constructed measure, we study its impact on the treasury market, stock market, and macroeconomic indicators. our dataset, models, and code are publicly available on huggingface and github under cc by-nc 4.0 license.",['acl-2023'],2023.acl-long.368.pdf
67,466,argu: a controllable factual argument generator,2023,"effective argumentation is essential towards a purposeful conversation with a satisfactory outcome. for example, persuading someone to reconsider smoking might involve empathetic, well founded arguments based on facts and expert opinions about its ill-effects and the consequences on one’s family. however, the automatic generation of high-quality factual arguments can be challenging. addressing existing controllability issues can make the recent advances in computational models for argument generation a potential solution. in this paper, we introduce argu: a neural argument generator capable of producing factual arguments from input facts and real-world concepts that can be explicitly controlled for stance and argument structure using walton’s argument scheme-based control codes. unfortunately, computational argument generation is a relatively new field and lacks datasets conducive to training. hence, we have compiled and released an annotated corpora of 69,428 arguments spanning six topics and six argument schemes, making it the largest publicly available corpus for identifying argument schemes; the paper details our annotation and dataset creation framework. we further experiment with an argument generation strategy that establishes an inference strategy by generating an “argument template” before actual argument generation. our results demonstrate that it is possible to automatically generate diverse arguments exhibiting different inference patterns for the same set of facts by using control codes based on argument schemes and stance.",['acl-2023'],2023.acl-long.466.pdf
68,560,a new direction in stance detection: target-stance extraction in the wild,2023,"stance detection aims to detect the stance toward a corresponding target. existing works use the assumption that the target is known in advance, which is often not the case in the wild. given a text from social media platforms, the target information is often unknown due to implicit mentions in the source text and it is infeasible to have manual target annotations at a large scale. therefore, in this paper, we propose a new task target-stance extraction (tse) that aims to extract the (target, stance) pair from the text. we benchmark the task by proposing a two-stage framework that first identifies the relevant target in the text and then detects the stance given the predicted target and text. specifically, we first propose two different settings: target classification and target generation, to identify the potential target from a given text. then we propose a multi-task approach that takes target prediction as the auxiliary task to detect the stance toward the predicted target. we evaluate the proposed framework on both in-target stance detection in which the test target is always seen in the training stage and zero-shot stance detection that needs to detect the stance for the targets that are unseen during the training phase. the new tse task can facilitate future research in the field of stance detection.",['acl-2023'],2023.acl-long.560.pdf
69,747,c-stance: a large dataset for chinese zero-shot stance detection,2023,"zero-shot stance detection (zssd) aims to determine whether the author of a text is in favor of, against, or neutral toward a target that is unseen during training. despite the growing attention on zssd, most recent advances in this task are limited to english and do not pay much attention to other languages such as chinese. to support zssd research, in this paper, we present c-stance that, to our knowledge, is the first chinese dataset for zero-shot stance detection. we introduce two challenging subtasks for zssd: target-based zssd and domain-based zssd. our dataset includes both noun-phrase targets and claim targets, covering a wide range of domains. we provide a detailed description and analysis of our dataset. to establish results on c-stance, we report performance scores using state-of-the-art deep learning models. we publicly release our dataset and code to facilitate future research.",['acl-2023'],2023.acl-long.747.pdf
70,752,topic-guided sampling for data-efficient multi-domain stance detection,2023,"the task of stance detection is concerned with identifying the attitudes expressed by an author towards a target of interest. this task spans a variety of domains ranging from social media opinion identification to detecting the stance for a legal claim. however, the framing of the task varies within these domains in terms of the data collection protocol, the label dictionary and the number of available annotations. furthermore, these stance annotations are significantly imbalanced on a per-topic and inter-topic basis. these make multi-domain stance detection challenging, requiring standardization and domain adaptation. to overcome this challenge, we propose topic efficient stance detection (tested), consisting of a topic-guided diversity sampling technique used for creating a multi-domain data efficient training set and a contrastive objective that is used for fine-tuning a stance classifier using the produced set. we evaluate the method on an existing benchmark of 16 datasets with in-domain, i.e. all topics seen and out-of-domain, i.e. unseen topics, experiments. the results show that the method outperforms the state-of-the-art with an average of 3.5 f1 points increase in-domain and is more generalizable with an averaged 10.2 f1 on out-of-domain evaluation while using <10% of the training data. we show that our sampling technique mitigates both inter- and per-topic class imbalances. finally, our analysis demonstrates that the contrastive learning objective allows the model for a more pronounced segmentation of samples with varying labels.",['acl-2023'],2023.acl-long.752.pdf
71,881,human-in-the-loop evaluation for early misinformation detection: a case study of covid-19 treatments,2023,"we present a human-in-the-loop evaluation framework for fact-checking novel misinformation claims and identifying social media messages that support them. our approach extracts check-worthy claims, which are aggregated and ranked for review. stance classifiers are then used to identify tweets supporting novel misinformation claims, which are further reviewed to determine whether they violate relevant policies. to demonstrate the feasibility of our approach, we develop a baseline system based on modern nlp methods for human-in-the-loop fact-checking in the domain of covid-19 treatments. we make our data and detailed annotation guidelines available to support the evaluation of human-in-the-loop systems that identify novel misinformation directly from raw user-generated content.",['acl-2023'],2023.acl-long.881.pdf
72,127,zero-shot and few-shot stance detection on varied topics via conditional generation,2023,"zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. in this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. we further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. we also verify the effectiveness of target-related wikipedia knowledge with the generation framework. experiments show that our proposed method significantly outperforms several strong baselines on vast, and achieves new state-of-the-art performance.",['acl-2023'],2023.acl-short.127.pdf
73,70,adversarial network with external knowledge for zero-shot stance detection,2023,"“zero-shot stance detection intends to detect previously unseen targets’ stances in the testingphase. however, achieving this goal can be difficult, as it requires minimizing the domain trans-fer between different targets, and improving the model’s inference and generalization abilities. to address this challenge, we propose an adversarial network with external knowledge (anek)model. specifically, we adopt adversarial learning based on pre-trained models to learn transfer-able knowledge from the source targets, thereby enabling the model to generalize well to unseentargets. additionally, we incorporate sentiment information and common sense knowledge intothe contextual representation to further enhance the model’s understanding. experimental re-sults on several datasets reveal that our method achieves excellent performance, demonstratingits validity and feasibility.”",['ccl-2023'],2023.ccl-1.70.pdf
74,67,conclusion-based counter-argument generation,2023,"in real-world debates, the most common way to counter an argument is to reason against its main point, that is, its conclusion. existing work on the automatic generation of natural language counter-arguments does not address the relation to the conclusion, possibly because many arguments leave their conclusion implicit. in this paper, we hypothesize that the key to effective counter-argument generation is to explicitly model the argument’s conclusion and to ensure that the stance of the generated counter is opposite to that conclusion. in particular, we propose a multitask approach that jointly learns to generate both the conclusion and the counter of an input argument. the approach employs a stance-based ranking component that selects the counter from a diverse set of generated candidates whose stance best opposes the generated conclusion. in both automatic and manual evaluation, we provide evidence that our approach generates more relevant and stance-adhering counters than strong baselines.",['eacl-2023'],2023.eacl-main.67.pdf
75,9,panacea: an automated misinformation detection system on covid-19,2023,"in this demo, we introduce a web-based misinformation detection system panacea on covid-19 related claims, which has two modules, fact-checking and rumour detection. our fact-checking module, which is supported by novel natural language inference methods with a self-attention network, outperforms state-of-the-art approaches. it is also able to give automated veracity assessment and ranked supporting evidence with the stance towards the claim to be checked. in addition, panacea adapts the bi-directional graph convolutional networks model, which is able to detect rumours based on comment networks of related tweets, instead of relying on the knowledge base. this rumour detection module assists by warning the users in the early stages when a knowledge base may not be available.",['eacl-2023'],2023.eacl-demo.9.pdf
76,259,support or refute: analyzing the stance of evidence to detect out-of-context mis- and disinformation,2023,"mis- and disinformation online have become a major societal problem as major sources of online harms of different kinds. one common form of mis- and disinformation is out-of-context (ooc) information, where different pieces of information are falsely associated, e.g., a real image combined with a false textual caption or a misleading textual description. although some past studies have attempted to defend against ooc mis- and disinformation through external evidence, they tend to disregard the role of different pieces of evidence with different stances. motivated by the intuition that the stance of evidence represents a bias towards different detection results, we propose a stance extraction network (sen) that can extract the stances of different pieces of multi-modal evidence in a unified framework. moreover, we introduce a support-refutation score calculated based on the co-occurrence relations of named entities into the textual sen. extensive experiments on a public large-scale dataset demonstrated that our proposed method outperformed the state-of-the-art baselines, with the best model achieving a performance gain of 3.2% in accuracy.",['emnlp-2023'],2023.emnlp-main.259.pdf
77,361,why should this article be deleted? transparent stance detection in multilingual wikipedia editor discussions,2023,"the moderation of content on online platforms is usually non-transparent. on wikipedia, however, this discussion is carried out publicly and editors are encouraged to use the content moderation policies as explanations for making moderation decisions. currently, only a few comments explicitly mention those policies – 20% of the english ones, but as few as 2% of the german and turkish comments. to aid in this process of understanding how content is moderated, we construct a novel multilingual dataset of wikipedia editor discussions along with their reasoning in three languages. the dataset contains the stances of the editors (keep, delete, merge, comment), along with the stated reason, and a content moderation policy, for each edit decision. we demonstrate that stance and corresponding reason (policy) can be predicted jointly with a high degree of accuracy, adding transparency to the decision-making process. we release both our joint prediction models and the multilingual content moderation dataset for further research on automated transparent content moderation.",['emnlp-2023'],2023.emnlp-main.361.pdf
78,368,automatic debate evaluation with argumentation semantics and natural language argument graph networks,2023,"the lack of annotated data on professional argumentation and complete argumentative debates has led to the oversimplification and the inability of approaching more complex natural language processing tasks. such is the case of the automatic evaluation of complete professional argumentative debates. in this paper, we propose an original hybrid method to automatically predict the winning stance in this kind of debates. for that purpose, we combine concepts from argumentation theory such as argumentation frameworks and semantics, with transformer-based architectures and neural graph networks. furthermore, we obtain promising results that lay the basis on an unexplored new instance of the automatic analysis of natural language arguments.",['emnlp-2023'],2023.emnlp-main.368.pdf
79,582,orchid: a chinese debate corpus for target-independent stance detection and argumentative dialogue summarization,2023,"dialogue agents have been receiving increasing attention for years, and this trend has been further boosted by the recent progress of large language models (llms). stance detection and dialogue summarization are two core tasks of dialogue agents in application scenarios that involve argumentative dialogues. however, research on these tasks is limited by the insufficiency of public datasets, especially for non-english languages. to address this language resource gap in chinese, we present orchid (oral chinese debate), the first chinese dataset for benchmarking target-independent stance detection and debate summarization. our dataset consists of 1,218 real-world debates that were conducted in chinese on 476 unique topics, containing 2,436 stance-specific summaries and 14,133 fully annotated utterances. besides providing a versatile testbed for future research, we also conduct an empirical study on the dataset and propose an integrated task. the results show the challenging nature of the dataset and suggest a potential of incorporating stance detection in summarization for argumentative dialogue.",['emnlp-2023'],2023.emnlp-main.582.pdf
80,666,cross-lingual cross-target stance detection with dual knowledge distillation framework,2023,"stance detection aims to identify the user’s attitude toward specific targets from text, which is an important research area in text mining and benefits a variety of application domains. existing studies on stance detection were conducted mainly in english. due to the low-resource problem in most non-english languages, cross-lingual stance detection was proposed to transfer knowledge from high-resource (source) language to low-resource (target) language. however, previous research has ignored the practical issue of no labeled training data available in target language. moreover, target inconsistency in cross-lingual stance detection brings about the additional issue of unseen targets in target language, which in essence requires the transfer of both language and target-oriented knowledge from source to target language. to tackle these challenging issues, in this paper, we propose the new task of cross-lingual cross-target stance detection and develop the first computational work with dual knowledge distillation. our proposed framework designs a cross-lingual teacher and a cross-target teacher using the source language data and a dual distillation process that transfers the two types of knowledge to target language. to bridge the target discrepancy between languages, cross-target teacher mines target category information and generalizes it to the unseen targets in target language via category-oriented learning. experimental results on multilingual stance datasets demonstrate the effectiveness of our method compared to the competitive baselines.",['emnlp-2023'],2023.emnlp-main.666.pdf
81,694,tata: stance detection via topic-agnostic and topic-aware embeddings,2023,"stance detection is important for understanding different attitudes and beliefs on the internet. however, given that a passage’s stance toward a given topic is often highly dependent on that topic, building a stance detection model that generalizes to unseen topics is difficult. in this work, we propose using contrastive learning as well as an unlabeled dataset of news articles that cover a variety of different topics to train topic-agnostic/tag and topic-aware/taw embeddings for use in downstream stance detection. combining these embeddings in our full tata model, we achieve state-of-the-art performance across several public stance detection datasets (0.771 f1-score on the zero-shot vast dataset). we release our code and data at https://github.com/hanshanley/tata.",['emnlp-2023'],2023.emnlp-main.694.pdf
82,776,identification of multimodal stance towards frames of communication,2023,"frames of communication are often evoked in multimedia documents. when an author decides to add an image to a text, one or both of the modalities may evoke a communication frame. moreover, when evoking the frame, the author also conveys her/his stance towards the frame. until now, determining if the author is in favor of, against or has no stance towards the frame was performed automatically only when processing texts. this is due to the absence of stance annotations on multimedia documents. in this paper we introduce mmvax-stance, a dataset of 11,300 multimedia documents retrieved from social media, which have stance annotations towards 113 different frames of communication. this dataset allowed us to experiment with several models of multimedia stance detection, which revealed important interactions between texts and images in the inference of stance towards communication frames. when inferring the text/image relations, a set of 46,606 synthetic examples of multimodal documents with known stance was generated. this greatly impacted the quality of identifying multimedia stance, yielding an improvement of 20% in f1-score.",['emnlp-2023'],2023.emnlp-main.776.pdf
83,972,stance detection on social media with background knowledge,2023,"identifying users’ stances regarding specific targets/topics is a significant route to learning public opinion from social media platforms. most existing studies of stance detection strive to learn stance information about specific targets from the context, in order to determine the user’s stance on the target. however, in real-world scenarios, we usually have a certain understanding of a target when we express our stance on it. in this paper, we investigate stance detection from a novel perspective, where the background knowledge of the targets is taken into account for better stance detection. to be specific, we categorize background knowledge into two categories: episodic knowledge and discourse knowledge, and propose a novel knowledge-augmented stance detection (kasd) framework. for episodic knowledge, we devise a heuristic retrieval algorithm based on the topic to retrieve the wikipedia documents relevant to the sample. further, we construct a prompt for chatgpt to filter the wikipedia documents to derive episodic knowledge. for discourse knowledge, we construct a prompt for chatgpt to paraphrase the hashtags, references, etc., in the sample, thereby injecting discourse knowledge into the sample. experimental results on four benchmark datasets demonstrate that our kasd achieves state-of-the-art performance in in-target and zero-shot stance detection.",['emnlp-2023'],2023.emnlp-main.972.pdf
84,104,topic ontologies for arguments,2023,"many computational argumentation tasks, such as stance classification, are topic-dependent: the effectiveness of approaches to these tasks depends largely on whether they are trained with arguments on the same topics as those on which they are tested. the key question is: what are these training topics? to answer this question, we take the first step of mapping the argumentation landscape with the argument ontology (tao). tao draws on three authoritative sources for argument topics: the world economic forum, wikipedia’s list of controversial topics, and debatepedia. by comparing the topics in our ontology with those in 59 argument corpora, we perform the first comprehensive assessment of their topic coverage. while tao already covers most of the corpus topics, the corpus topics barely cover all the topics in tao. this points to a new goal for corpus construction to achieve a broad topic coverage and thus better generalizability of computational argumentation approaches.","['findings-2023', 'eacl-2023']",2023.findings-eacl.104.pdf
85,59,aqe: argument quadruplet extraction via a quad-tagging augmented generative approach,2023,"argument mining involves multiple sub-tasks that automatically identify argumentative elements, such as claim detection, evidence extraction, stance classification, etc. however, each subtask alone is insufficient for a thorough understanding of the argumentative structure and reasoning process. to learn a complete view of an argument essay and capture the interdependence among argumentative components, we need to know what opinions people hold (i.e., claims), why those opinions are valid (i.e., supporting evidence), which source the evidence comes from (i.e., evidence type), and how those claims react to the debating topic (i.e., stance). in this work, we for the first time propose a challenging argument quadruplet extraction task (aqe), which can provide an all-in-one extraction of four argumentative components, i.e., claims, evidence, evidence types, and stances. to support this task, we construct a large-scale and challenging dataset. however, there is no existing method that can solve the argument quadruplet extraction. to fill this gap, we propose a novel quad-tagging augmented generative approach, which leverages a quadruplet tagging module to augment the training of the generative framework. the experimental results on our dataset demonstrate the empirical superiority of our proposed approach over several strong baselines.","['findings-2023', 'acl-2023']",2023.findings-acl.59.pdf
86,115,disentangling aspect and stance via a siamese autoencoder for aspect clustering of vaccination opinions,2023,"mining public opinions about vaccines from social media has been increasingly relevant to analyse trends in public debates and to provide quick insights to policy-makers. however, the application of existing models has been hindered by the wide variety of users’ attitudes and the new aspects continuously arising in the public debate. existing approaches, frequently framed via well-known tasks, such as aspect classification or text span detection, make direct usage of the supervision information constraining the models to predefined aspect classes, while still not distinguishing those aspects from users’ stances. as a result, this has significantly hindered the dynamic integration of new aspects. we thus propose a model, namely disentangled opinion clustering (doc), for vaccination opinion mining from social media. doc is able to disentangle users’ stances from opinions via a disentangling attention mechanism and a swapping-autoencoder, and is designed to process unseen aspect categories via a clustering approach, leveraging clustering-friendly representations induced by out-of-the-box sentence-bert encodings and disentangling mechanisms. we conduct a thorough experimental assessment demonstrating the benefit of the disentangling mechanisms and cluster-based approach on both the quality of aspect clusters and the generalization across new aspect categories, outperforming existing methodologies on aspect-based opinion mining.","['findings-2023', 'acl-2023']",2023.findings-acl.115.pdf
87,393,distilling calibrated knowledge for stance detection,2023,"stance detection aims to determine the position of an author toward a target and provides insights into people’s views on controversial topics such as marijuana legalization. despite recent progress in this task, most existing approaches use hard labels (one-hot vectors) during training, which ignores meaningful signals among categories offered by soft labels. in this work, we explore knowledge distillation for stance detection and present a comprehensive analysis. our contributions are: 1) we propose to use knowledge distillation over multiple generations in which a student is taken as a new teacher to transfer knowledge to a new fresh student; 2) we propose a novel dynamic temperature scaling for knowledge distillation to calibrate teacher predictions in each generation step. extensive results on three stance detection datasets show that knowledge distillation benefits stance detection and a teacher is able to transfer knowledge to a student more smoothly via calibrated guiding signals. we publicly release our code to facilitate future research.","['findings-2023', 'acl-2023']",2023.findings-acl.393.pdf
88,399,target-oriented relation alignment for cross-lingual stance detection,2023,"stance detection is an important task in text mining and social media analytics, aiming to automatically identify the user’s attitude toward a specific target from text, and has wide applications in a variety of domains. previous work on stance detection has mainly focused on monolingual setting. to address the problem of imbalanced language resources, cross-lingual stance detection is proposed to transfer the knowledge learned from a high-resource (source) language (typically english) to another low-resource (target) language. however, existing research on cross-lingual stance detection has ignored the inconsistency in the occurrences and distributions of targets between languages, which consequently degrades the performance of stance detection in low-resource languages. in this paper, we first identify the target inconsistency issue in cross-lingual stance detection, and propose a fine-grained target-oriented relation alignment (tara) method for the task, which considers both target-level associations and language-level alignments. specifically, we propose the target relation graph to learn the in-language and cross-language target associations. we further devise the relation alignment strategy to enable knowledge transfer between semantically correlated targets across languages. experimental results on the representative datasets demonstrate the effectiveness of our method compared to competitive methods under variant settings.","['findings-2023', 'acl-2023']",2023.findings-acl.399.pdf
89,174,multi-label and multi-target sampling of machine annotation for computational stance detection,2023,"data collection from manual labeling provides domain-specific and task-aligned supervision for data-driven approaches, and a critical mass of well-annotated resources is required to achieve reasonable performance in natural language processing tasks. however, manual annotations are often challenging to scale up in terms of time and budget, especially when domain knowledge, capturing subtle semantic features, and reasoning steps are needed. in this paper, we investigate the efficacy of leveraging large language models on automated labeling for computational stance detection. we empirically observe that while large language models show strong potential as an alternative to human annotators, their sensitivity to task-specific instructions and their intrinsic biases pose intriguing yet unique challenges in machine annotation. we introduce a multi-label and multi-target sampling strategy to optimize the annotation quality. experimental results on the benchmark stance detection corpora show that our method can significantly improve performance and learning efficacy.","['findings-2023', 'emnlp-2023']",2023.findings-emnlp.174.pdf
90,273,chain-of-thought embeddings for stance detection on social media,2023,"stance detection on social media is challenging for large language models (llms), as emerging slang and colloquial language in online conversations often contain deeply implicit stance labels. chain-of-thought (cot) prompting has recently been shown to improve performance on stance detection tasks — alleviating some of these issues. however, cot prompting still struggles with implicit stance identification. this challenge arises because many samples are initially challenging to comprehend before a model becomes familiar with the slang and evolving knowledge related to different topics, all of which need to be acquired through the training data. in this study, we address this problem by introducing cot embeddings which improve cot performance on stance detection tasks by embedding cot reasonings and integrating them into a traditional roberta-based stance detection pipeline. our analysis demonstrates that 1) text encoders can leverage cot reasonings with minor errors or hallucinations that would otherwise distort the cot output label. 2) text encoders can overlook misleading cot reasoning when a sample’s prediction heavily depends on domain-specific patterns. our model achieves sota performance on multiple stance detection datasets collected from social media.","['findings-2023', 'emnlp-2023']",2023.findings-emnlp.273.pdf
91,295,"toxicity, morality, and speech act guided stance detection",2023,"in this work, we focus on the task of determining the public attitude toward various social issues discussed on social media platforms. platforms such as twitter, however, are often used to spread misinformation, fake news through polarizing views. existing literature suggests that higher levels of toxicity prevalent in twitter conversations often spread negativity and delay addressing issues. further, the embedded moral values and speech acts specifying the intention of the tweet correlate with public opinions expressed on various topics. however, previous works, which mainly focus on stance detection, either ignore the speech act, toxic, and moral features of these tweets that can collectively help capture public opinion or lack an efficient architecture that can detect the attitudes across targets. therefore, in our work, we focus on the main task of stance detection by exploiting the toxicity, morality, and speech act as auxiliary tasks. we propose a multitasking model twisted that initially extracts the valence, arousal, and dominance aspects hidden in the tweets and injects the emotional sense into the embedded text followed by an efficient attention framework to correctly detect the tweet’s stance by using the shared features of toxicity, morality, and speech acts present in the tweet. extensive experiments conducted on 4 benchmark stance detection datasets (semeval-2016, p-stance, covid19-stance, and climatechange) comprising different domains demonstrate the effectiveness and generalizability of our approach.","['findings-2023', 'emnlp-2023']",2023.findings-emnlp.295.pdf
92,387,investigating online community engagement through stancetaking,2023,"much work has explored lexical and semantic variation in online communities, and drawn connections to community identity and user engagement patterns. communities also express identity through the sociolinguistic concept of stancetaking. large-scale computational work on stancetaking has explored community similarities in their preferences for stance markers – words that serve to indicate aspects of a speaker’s stance – without considering the stance-relevant properties of the contexts in which stance markers are used. we propose representations of stance contexts for 1798 reddit communities and show how they capture community identity patterns distinct from textual or marker similarity measures. we also relate our stance context representations to broader inter- and intra-community engagement patterns, including cross-community posting patterns and social network properties of communities. our findings highlight the strengths of using rich properties of stance as a way of revealing community identity and engagement patterns in online multi-community spaces.","['findings-2023', 'emnlp-2023']",2023.findings-emnlp.387.pdf
93,432,dynamic stance: modeling discussions by labeling the interactions,2023,"stance detection is an increasingly popular task that has been mainly modeled as a static task, by assigning the expressed attitude of a text toward a given topic. such a framing presents limitations, with trained systems showing poor generalization capabilities and being strongly topic-dependent. in this work, we propose modeling stance as a dynamic task, by focusing on the interactions between a message and their replies. for this purpose, we present a new annotation scheme that enables the categorization of all kinds of textual interactions. as a result, we have created a new corpus, the dynamic stance corpus (dysc), consisting of three datasets in two middle-resourced languages: catalan and dutch. our data analysis further supports our modeling decisions, empirically showing differences between the annotation of stance in static and dynamic contexts. we fine-tuned a series of monolingual and multilingual models on dysc, showing portability across topics and languages.","['findings-2023', 'emnlp-2023']",2023.findings-emnlp.432.pdf
94,787,multilingual coarse political stance classification of media. the editorial line of a chatgpt and bard newspaper,2023,"neutrality is difficult to achieve and, in politics, subjective. traditional media typically adopt an editorial line that can be used by their potential readers as an indicator of the media bias. several platforms currently rate news outlets according to their political bias. the editorial line and the ratings help readers in gathering a balanced view of news. but in the advent of instruction-following language models, tasks such as writing a newspaper article can be delegated to computers. without imposing a biased persona, where would an ai-based news outlet lie within the bias ratings? in this work, we use the ratings of authentic news outlets to create a multilingual corpus of news with coarse stance annotations (left and right) along with automatically extracted topic annotations. we show that classifiers trained on this data are able to identify the editorial line of most unseen newspapers in english, german, spanish and catalan. we then apply the classifiers to 101 newspaper-like articles written by chatgpt and bard in the 4 languages at different time periods. we observe that, similarly to traditional newspapers, chatgpt editorial line evolves with time and, being a data-driven system, the stance of the generated articles differs among languages.","['findings-2023', 'emnlp-2023']",2023.findings-emnlp.787.pdf
95,901,beyond testers’ biases: guiding model testing with knowledge bases using llms,2023,"current model testing work has mostly focused on creating test cases. identifying what to test is a step that is largely ignored and poorly supported. we propose weaver, an interactive tool that supports requirements elicitation for guiding model testing. weaver uses large language models to generate knowledge bases and recommends concepts from them interactively, allowing testers to elicit requirements for further testing. weaver provides rich external knowledge to testers and encourages testers to systematically explore diverse concepts beyond their own biases. in a user study, we show that both nlp experts and non-experts identified more, as well as more diverse concepts worth testing when using weaver. collectively, they found more than 200 failing test cases for stance detection with zero-shot chatgpt. our case studies further show that weaver can help practitioners test models in real-world settings, where developers define more nuanced application scenarios (e.g., code understanding and transcript summarization) using llms.","['findings-2023', 'emnlp-2023']",2023.findings-emnlp.901.pdf
96,24,framing in the presence of supporting data: a case study in u.s. economic news,2024,"the mainstream media has much leeway in what it chooses to cover and how it covers it. these choices have real-world consequences on what people know and their subsequent behaviors. however, the lack of objective measures to evaluate editorial choices makes research in this area particularly difficult. in this paper, we argue that there are newsworthy topics where objective measures exist in the form of supporting data and propose a computational framework to analyze editorial choices in this setup. we focus on the economy because the reporting of economic indicators presents us with a relatively easy way to determine both the selection and framing of various publications. their values provide a ground truth of how the economy is doing relative to how the publications choose to cover it. to do this, we define frame prediction as a set of interdependent tasks. at the article level, we learn to identify the reported stance towards the general state of the economy. then, for every numerical quantity reported in the article, we learn to identify whether it corresponds to an economic indicator and whether it is being reported in a positive or negative way. to perform our analysis, we track six american publishers and each article that appeared in the top 10 slots of their landing page between 2015 and 2023.",['acl-2024'],2024.acl-long.24.pdf
97,49,tree-of-counterfactual prompting for zero-shot stance detection,2024,"stance detection enables the inference of attitudes from human communications. automatic stance identification was mostly cast as a classification problem. however, stance decisions involve complex judgments, which can be nowadays generated by prompting large language models (llms). in this paper we present a new method for stance identification which (1) relies on a new prompting framework, called tree-of-counterfactual prompting; (2) operates not only on textual communications, but also on images; (3) allows more than one stance object type; and (4) requires no examples of stance attribution, thus it is a “tabula rasa” zero-shot stance detection (tr-zssd) method. our experiments indicate surprisingly promising results, outperforming fine-tuned stance detection systems.",['acl-2024'],2024.acl-long.49.pdf
98,80,transitive consistency constrained learning for entity-to-entity stance detection,2024,"entity-to-entity stance detection identifies the stance between a pair of entities with a directed link that indicates the source, target and polarity. it is a streamlined task without the complex dependency structure for structural sentiment analysis, while it is more informative compared to most previous work assuming that the source is the author. previous work performs entity-to-entity stance detection training on individual entity pairs. however, stances between inter-connected entity pairs may be correlated. in this paper, we propose transitive consistency constrained learning, which first finds connected entity pairs and their stances, and adds an additional objective to enforce the transitive consistency. we explore consistency training on both classification-based and generation-based models and conduct experiments to compare consistency training with previous work and large language models with in-context learning. experimental results illustrate that the inter-correlation of stances in political news can be used to improve the entity-to-entity stance detection model, while overly strict consistency enforcement may have a negative impact. in addition, we find that large language models struggle with predicting link direction and neutral labels in this task.",['acl-2024'],2024.acl-long.80.pdf
99,509,whose preferences? differences in fairness preferences and their impact on the fairness of ai utilizing human feedback,2024,"there is a growing body of work on learning from human feedback to align various aspects of machine learning systems with human values and preferences. we consider the setting of fairness in content moderation, in which human feedback is used to determine how two comments — referencing different sensitive attribute groups — should be treated in comparison to one another. with a novel dataset collected from prolific and mturk, we find significant gaps in fairness preferences depending on the race, age, political stance, educational level, and lgbtq+ identity of annotators. we also demonstrate that demographics mentioned in text have a strong influence on how users perceive individual fairness in moderation. further, we find that differences also exist in downstream classifiers trained to predict human preferences. finally, we observe that an ensemble, giving equal weight to classifiers trained on annotations from different demographics, performs better for different demographic intersections; compared to a single classifier that gives equal weight to each annotation.",['acl-2024'],2024.acl-long.509.pdf
100,650,gunstance: stance detection for gun control and gun regulation,2024,"the debate surrounding gun control and gun regulation in the united states has intensified in the wake of numerous mass shooting events. as perspectives on this matter vary, it becomes increasingly important to comprehend individuals’ positions. stance detection, the task of determining an author’s position towards a proposition or target, has gained attention for its potential use in understanding public perceptions towards controversial topics and identifying the best strategies to address public concerns. in this paper, we present gunstance, a dataset of tweets pertaining to shooting events, focusing specifically on the controversial topics of “banning guns” versus “regulating guns.” the tweets in the dataset are sourced from discussions on twitter following various shooting incidents in the united states. amazon mechanical turk was used to manually annotate a subset of the tweets relevant to the targets of interest (“banning guns” and “regulating guns”) into three classes: in-favor, against, and neutral. the remaining unlabeled tweets are included in the dataset to facilitate studies on semi-supervised learning (ssl) approaches that can help address the scarcity of the labeled data in stance detection tasks. furthermore, we propose a hybrid approach that combines curriculum-based ssl and large language models (llm), and show that the proposed approach outperforms supervised, semi-supervised, and llm-based zero-shot models in most experiments on our assembled dataset.",['acl-2024'],2024.acl-long.650.pdf
101,795,how to handle different types of out-of-distribution scenarios in computational argumentation? a comprehensive and fine-grained field study,2024,"the advent of pre-trained language models (lms) has markedly advanced natural language processing, but their efficacy in out-of-distribution (ood) scenarios remains a significant challenge. computational argumentation (ca), modeling human argumentation processes, is a field notably impacted by these challenges because complex annotation schemes and high annotation costs naturally lead to resources barely covering the multiplicity of available text sources and topics. due to this data scarcity, generalization to data from uncovered covariant distributions is a common challenge for ca tasks like stance detection or argument classification. this work systematically assesses lms’ capabilities for such ood scenarios. while previous work targets specific ood types like topic shifts or ood uniformly, we address three prevalent ood scenarios in ca: topic shift, domain shift, and language shift. our findings challenge the previously asserted general superiority of in-context learning (icl) for ood. we find that the efficacy of such learning paradigms varies with the type of ood. specifically, while icl excels for domain shifts, prompt-based fine-tuning surpasses for topic shifts. to sum up, we navigate the heterogeneity of ood scenarios in ca and empirically underscore the potential of base-sized lms in overcoming these challenges.",['acl-2024'],2024.acl-long.795.pdf
102,838,ez-stance: a large dataset for english zero-shot stance detection,2024,"zero-shot stance detection (zssd) aims to determine whether the author of a text is in favor, against, or neutral toward a target that is unseen during training. in this paper, we present ez-stance, a large english zssd dataset with 47,316 annotated text-target pairs. in contrast to vast, which is the only other large existing zssd dataset for english, ez-stance is 2.5 times larger, includes both noun-phrase targets and claim targets that cover a wide range of domains, provides two challenging subtasks for zssd: target-based zssd and domain-based zssd, and contains much harder examples for the neutral class. we evaluate ez-stance using state-of-the-art deep learning models. furthermore, we propose to transform zssd into the nli task by applying simple yet effective prompts to noun-phrase targets. our experimental results show that ez-stance is a challenging new benchmark, which provides significant research opportunities on english zssd. we publicly release our dataset and code at https://github.com/chenyez/ez-stance.",['acl-2024'],2024.acl-long.838.pdf
103,7,stance detection with explanations,2024,"identification of stance has recently gained a lot of attention with the extreme growth of fake news and filter bubbles. over the last decade, many feature-based and deep-learning approaches have been proposed to solve stance detection. however, almost none of the existing works focus on providing a meaningful explanation for their prediction. in this work, we study stance detection with an emphasis on generating explanations for the predicted stance by capturing the pivotal argumentative structure embedded in a document. we propose to build a stance tree that utilizes rhetorical parsing to construct an evidence tree and to use dempster shafer theory to aggregate the evidence. human studies show that our unsupervised technique of generating stance explanations outperforms the sota extractive summarization method in terms of informativeness, non-redundancy, coverage, and overall quality. furthermore, experiments show that our explanation-based stance prediction excels or matches the performance of the sota model on various benchmark datasets.",['cl-2024'],2024.cl-1.7.pdf
104,8,the role of typological feature prediction in nlp and linguistics,2024,"computational typology has gained traction in the field of natural language processing (nlp) in recent years, as evidenced by the increasing number of papers on the topic and the establishment of a special interest group on the topic (sigtyp), including the organization of successful workshops and shared tasks. a considerable amount of work in this sub-field is concerned with prediction of typological features, for example, for databases such as the world atlas of language structures (wals) or grambank. prediction is argued to be useful either because (1) it allows for obtaining feature values for relatively undocumented languages, alleviating the sparseness in wals, in turn argued to be useful for both nlp and linguistics; and (2) it allows us to probe models to see whether or not these typological features are encapsulated in, for example, language representations. in this article, we present a critical stance concerning prediction of typological features, investigating to what extent this line of research is aligned with purported needs—both from the perspective of nlp practitioners, and perhaps more importantly, from the perspective of linguists specialized in typology and language documentation. we provide evidence that this line of research in its current state suffers from a lack of interdisciplinary alignment. based on an extensive survey of the linguistic typology community, we present concrete recommendations for future research in order to improve this alignment between linguists and nlp researchers, beyond the scope of typological feature prediction.",['cl-2024'],2024.cl-2.8.pdf
105,92,style-news: incorporating stylized news generation and adversarial verification for neural fake news detection,2024,"with the improvements in generative models, the issues of producing hallucinations in various domains (e.g., law, writing) have been brought to people’s attention due to concerns about misinformation. in this paper, we focus on neural fake news, which refers to content generated by neural networks aiming to mimic the style of real news to deceive people. to prevent harmful disinformation spreading fallaciously from malicious social media (e.g., content farms), we propose a novel verification framework, style-news, using publisher metadata to imply a publisher’s template with the corresponding text types, political stance, and credibility. based on threat modeling aspects, a style-aware neural news generator is introduced as an adversary for generating news content conditioning for a specific publisher, and style and source discriminators are trained to defend against this attack by identifying which publisher the style corresponds with, and discriminating whether the source of the given news is human-written or machine-generated. to evaluate the quality of the generated content, we integrate various dimensional metrics (language fluency, content preservation, and style adherence) and demonstrate that style-news significantly outperforms the previous approaches by a margin of 0.35 for fluency, 15.24 for content, and 0.38 for style at most. moreover, our discriminative model outperforms state-of-the-art baselines in terms of publisher prediction (up to 4.64%) and neural fake news detection (+6.94% 31.72%). we plan to release our style-news publicly, with the aim of improving neural fake news detection.",['eacl-2024'],2024.eacl-long.92.pdf
106,107,unsupervised stance detection for social media discussions: a generic baseline,2024,"with the ever-growing use of social media to express opinions on the national and international stage, unsupervised methods of stance detection are increasingly important to handle the task without costly annotation of data. the current unsupervised state-of-the-art models are designed for specific network types, either homophilic or heterophilic, and they fail to generalize to both. in this paper, we first analyze the generalization ability of recent baselines to these two very different network types. then, we conduct extensive experiments with a baseline model based on text embeddings propagated with a graph neural network that generalizes well to heterophilic and homophilic networks. we show that it outperforms, on average, other state-of-the-art methods across the two network types. additionally, we show that combining textual and network information outperforms using text only, and that the language model size has only a limited impact on the model performance.",['eacl-2024'],2024.eacl-long.107.pdf
107,108,putting context in context: the impact of discussion structure on text classification,2024,"current text classification approaches usually focus on the content to be classified. contextual aspects (both linguistic and extra-linguistic) are usually neglected, even in tasks based on online discussions. still in many cases the multi-party and multi-turn nature of the context from which these elements are selected can be fruitfully exploited. in this work, we propose a series of experiments on a large dataset for stance detection in english, in which we evaluate the contribution of different types of contextual information, i.e. linguistic, structural and temporal, by feeding them as natural language input into a transformer-based model. we also experiment with different amounts of training data and analyse the topology of local discussion networks in a privacy-compliant way. results show that structural information can be highly beneficial to text classification but only under certain circumstances (e.g. depending on the amount of training data and on discussion chain complexity). indeed, we show that contextual information on smaller datasets from other classification tasks does not yield significant improvements. our framework, based on local discussion networks, allows the integration of structural information while minimising user profiling, thus preserving their privacy.",['eacl-2024'],2024.eacl-long.108.pdf
108,24,sig-networks toolkit: signature networks for longitudinal language modelling,2024,"we present an open-source, pip installable toolkit, sig-networks, the first of its kind for longitudinal language modelling. a central focus is the incorporation of signature-based neural network models, which have recently shown success in temporal tasks. we apply and extend published research providing a full suite of signature-based models. their components can be used as pytorch building blocks in future architectures. sig-networks enables task-agnostic dataset plug-in, seamless preprocessing for sequential data, parameter flexibility, automated tuning across a range of models. we examine signature networks under three different nlp tasks of varying temporal granularity: counselling conversations, rumour stance switch and mood changes in social media threads, showing sota performance in all three, and provide guidance for future tasks. we release the toolkit as a pytorch package with an introductory video, git repositories for preprocessing and modelling including sample notebooks on the modeled nlp tasks.",['eacl-2024'],2024.eacl-demo.24.pdf
109,128,“tell me who you are and i tell you how you argue”: predicting stances and arguments for stakeholder groups,2024,"argument mining has focused so far mainly on the identification, extraction, and formalization of arguments. an important yet unaddressedtask consists in the prediction of the argumentative behavior of stakeholders in a debate. predicting the argumentative behavior in advance can support foreseeing issues in public policy making or help recognize potential disagreements early on and help to resolve them. in this paper, we consider the novel task of predicting the argumentative behavior of individual stakeholders. we present argenst, a framework that relies on a recommender-based architecture to predict the stance and the argumentative main point on a specific controversial topic for a given stakeholder, which is described in terms of a profile including properties related to demographic attributes, religious and political orientation, socio-economic background, etc. we evaluate our approach on the well-known debate.org dataset in terms of accuracy for predicting stance as well as in terms of similarity of the generated arguments to the ground truth arguments using bertscore. as part of a case study, we show how juries of members representing different stakeholder groups and perspectives can be assembled to simulate the public opinion on a given topic.","['findings-2024', 'naacl-2024']",2024.findings-naacl.128.pdf
110,155,dell: generating reactions and explanations for llm-based misinformation detection,2024,"large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. in this work, we propose dell that identifies three key stages in misinformation detection where llms could be incorporated as part of the pipeline: 1) llms could generate news reactions to represent diverse perspectives and simulate user-news interaction networks; 2) llms could generate explanations for proxy tasks (e.g., sentiment, stance) to enrich the contexts of news articles and produce experts specializing in various aspects of news understanding; 3) llms could merge task-specific experts and provide an overall prediction by incorporating the predictions and confidence scores of varying experts. extensive experiments on seven datasets with three llms demonstrate that dell outperforms state-of-the-art baselines by up to 16.8% in macro f1-score. further analysis reveals that the generated reactions and explanations are greatly helpful in misinformation detection, while our proposed llm-guided expert merging helps produce better-calibrated predictions.","['findings-2024', 'acl-2024']",2024.findings-acl.155.pdf
111,192,"pro-woman, anti-man? identifying gender bias in stance detection",2024,"gender bias has been widely observed in nlp models, which has the potential to perpetuate harmful stereotypes and discrimination. in this paper, we construct a dataset genderstance of 36k samples to measure gender bias in stance detection, determining whether models consistently predict the same stance for a particular gender group. we find that all models are gender-biased and prone to classify sentences that contain male nouns as against and those with female nouns as favor. moreover, extensive experiments indicate that sources of gender bias stem from the fine-tuning data and the foundation model itself. we will publicly release our code and dataset.","['findings-2024', 'acl-2024']",2024.findings-acl.192.pdf
112,304,play guessing game with llm: indirect jailbreak attack with implicit clues,2024,"with the development of llms, the security threats of llms are getting more and more attention. numerous jailbreak attacks have been proposed to assess the security defense of llms. current jailbreak attacks primarily utilize scenario camouflage techniques. however their explicitly mention of malicious intent will be easily recognized and defended by llms. in this paper, we propose an indirect jailbreak attack approach, puzzler, which can bypass the llm’s defensive strategies and obtain malicious response by implicitly providing llms with some clues about the original malicious query. in addition, inspired by the wisdom of “when unable to attack, defend” from sun tzu’s art of war, we adopt a defensive stance to gather clues about the original malicious query through llms. the experimental results indicate that the query success rate of the puzzler is 14.0%-82.7% higher than baselines on the most prominent llms. furthermore, when tested against the state-of-the-art jailbreak detection approaches, puzzler proves to be more effective at evading detection compared to baselines.","['findings-2024', 'acl-2024']",2024.findings-acl.304.pdf
113,586,evaluating large language model biases in persona-steered generation,2024,"the task of persona-steered text generation requires large language models (llms) to generate text that reflects the distribution of views that an individual fitting a persona could have. people have multifaceted personas, but prior work on bias in llm-generated opinions has only explored multiple-choice settings or one-dimensional personas. we define an incongruous persona as a persona with multiple traits where one trait makes its other traits less likely in human survey data, e.g. political liberals who support increased military spending. we find that llms are 9.7% less steerable towards incongruous personas than congruous ones, sometimes generating the stereotypical stance associated with its demographic rather than the target stance. models that we evaluate that are fine-tuned with reinforcement learning from human feedback (rlhf) are more steerable, especially towards stances associated with political liberals and women, but present significantly less diverse views of personas. we also find variance in llm steerability that cannot be predicted from multiple-choice opinion evaluation. our results show the importance of evaluating models in open-ended text generation, as it can surface new llm opinion biases. moreover, such a setup can shed light on our ability to steer models toward a richer and more diverse range of viewpoints.","['findings-2024', 'acl-2024']",2024.findings-acl.586.pdf
114,736,multi-modal stance detection: new datasets and model,2024,"stance detection is a challenging task that aims to identify public opinion from social media platforms with respect to specific targets. previous work on stance detection largely focused on pure texts. in this paper, we study multi-modal stance detection for tweets consisting of texts and images, which are prevalent in today’s fast-growing social media platforms where people often post multi-modal messages. to this end, we create five new multi-modal stance detection datasets of different domains based on twitter, in which each example consists of a text and an image. in addition, we propose a simple yet effective targeted multi-modal prompt tuning framework (tmpt), where target information is leveraged to learn multi-modal stance features from textual and visual modalities. experimental results on our five benchmark datasets show that the proposed tmpt achieves state-of-the-art performance in multi-modal stance detection.","['findings-2024', 'acl-2024']",2024.findings-acl.736.pdf
115,794,zerostance: leveraging chatgpt for open-domain stance detection via dataset generation,2024,"zero-shot stance detection that aims to detect the stance (typically against, favor, or neutral) towards unseen targets has attracted considerable attention. however, most previous studies only focus on targets from a single or limited text domains (e.g., financial domain), and thus zero-shot models cannot generalize well to unseen targets of diverse domains (e.g., political domain). in this paper, we consider a more realistic task, i.e., open-domain stance detection, which aims at training a model that is able to generalize well to unseen targets across multiple domains of interest. particularly, we propose a novel dataset generation method zerostance, which leverages chatgpt to construct a synthetic open-domain dataset chatstance that covers a wide range of domains. we then train an open-domain model on our synthetic dataset after proper data filtering. extensive results indicate that our model, when trained on this synthetic dataset, shows superior generalization to unseen targets of diverse domains over baselines on most benchmarks. our method requires only a task description in the form of a prompt and is much more cost-effective and data-efficient than previous methods. we will release our code and data to facilitate future research.","['findings-2024', 'acl-2024']",2024.findings-acl.794.pdf
116,796,reinforcement tuning for detecting stances and debunking rumors jointly with large language models,2024,"learning multi-task models for jointly detecting stance and verifying rumors poses challenges due to the need for training data of stance at post level and rumor veracity at claim level, which are difficult to obtain. to address this issue, we leverage large language models (llms) as the foundation annotators for the joint stance detection (sd) and rumor verification (rv) tasks, dubbed as jsdrv. we introduce a novel reinforcement tuning framework to enhance the joint predictive capabilities of llm-based sd and rv components. specifically, we devise a policy for selecting llm-annotated data at the two levels, employing a hybrid reward mechanism to choose high-quality labels for effective llm fine-tuning on both tasks. results demonstrate that jsdrv improves the capabilities of llms in the joint tasks, not only outperforming state-of-the-art methods but also generalizing to non-llms accommodated as task models.","['findings-2024', 'acl-2024']",2024.findings-acl.796.pdf
117,956,can llms speak for diverse people? tuning llms via debate to generate controllable controversial statements,2024,"making llms speak for different, especially minority groups of people, and generate statements supporting their diverse or even controversial perspectives is critical to creating an inclusive environment. however, existing llms lack sufficient controllability to the stance of their generated content, which often contains inconsistent, neutral, or biased statements. in this paper, we improve the controllability of llms in generating statements supporting an argument the user defined in the prompt. we find that multi-round debates between two llms with opposite stances generate higher-quality and more salient statements for each, which are important training data to improve the controllability of llms. motivated by this, we develop a novel debate & tuning (“debatune”) pipeline finetuning llms to generate the statements obtained via debate. to examine debatune, we curate the largest dataset of debate topics so far, which covers 710 controversial topics and corresponding arguments for each topic. evaluations by the gpt-4 judge with a novel controversy controllability metric show that llms’ capability of generating diverse perspectives is significantly improved by debatune. moreover, such controllability can be generalized to unseen topics, generating high-quality statements supporting controversial arguments.","['findings-2024', 'acl-2024']",2024.findings-acl.956.pdf
118,11,a challenge dataset and effective models for conversational stance detection,2024,"previous stance detection studies typically concentrate on evaluating stances within individual instances, thereby exhibiting limitations in effectively modeling multi-party discussions concerning the same specific topic, as naturally transpire in authentic social media interactions. this constraint arises primarily due to the scarcity of datasets that authentically replicate real social media contexts, hindering the research progress of conversational stance detection. in this paper, we introduce a new multi-turn conversation stance detection dataset (called mt-csd), which encompasses multiple targets for conversational stance detection. to derive stances from this challenging dataset, we propose a global-local attention network (glan) to address both long and short-range dependencies inherent in conversational data. notably, even state-of-the-art stance detection methods, exemplified by glan, exhibit an accuracy of only 50.47%, highlighting the persistent challenges in conversational stance detection. furthermore, our mt-csd dataset serves as a valuable resource to catalyze advancements in cross-domain stance detection, where a classifier is adapted from a different yet related target. we believe that mt-csd will contribute to advancing real-world applications of stance detection research. our source code, data, and models are available at https://github.com/nfq729/mt-csd.","['lrec-2024', 'coling-2024']",2024.lrec-main.11.pdf
119,88,analyzing the dynamics of climate change discourse on twitter: a new annotated corpus and multi-aspect classification,2024,"the discourse surrounding climate change on social media platforms has emerged as a significant avenue for understanding public sentiments, perspectives, and engagement with this critical global issue. the unavailability of publicly available datasets, coupled with ignoring the multi-aspect analysis of climate discourse on social media platforms, has underscored the necessity for further advancement in this area. to address this gap, in this paper, we present an extensive exploration of the intricate realm of climate change discourse on twitter, leveraging a meticulously annotated climaconvo dataset comprising 15,309 tweets. our annotations encompass a rich spectrum, including aspects like relevance, stance, hate speech, the direction of hate, and humor, offering a nuanced understanding of the discourse dynamics. we address the challenges inherent in dissecting online climate discussions and detail our comprehensive annotation methodology. in addition to annotations, we conduct benchmarking assessments across various algorithms for six tasks: relevance detection, stance detection, hate speech identification, direction and target, and humor analysis. this assessment enhances our grasp of sentiment fluctuations and linguistic subtleties within the discourse. our analysis extends to exploratory data examination, unveiling tweet distribution patterns, stance prevalence, and hate speech trends. employing sophisticated topic modeling techniques uncovers underlying thematic clusters, providing insights into the diverse narrative threads woven within the discourse. the findings present a valuable resource for researchers, policymakers, and communicators seeking to navigate the intricacies of climate change discussions. the dataset and resources for this paper are available at https://github.com/shucoll/climaconvo.","['lrec-2024', 'coling-2024']",2024.lrec-main.88.pdf
120,134,are text classifiers xenophobic? a country-oriented bias detection method with least confounding variables,2024,"classical bias detection methods used in machine learning are themselves biased because of the different confounding variables implied in the assessment of the initial biases. first they are using templates that are syntactically simple and distant from the target data on which the model will deployed. second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms. we propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. the idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes. in this work, we focus on named entity perturbations by applying a named entity recognition on target-domain data and modifying them accordingly to most common names or location of a target group (gender and country), and this for several morphosynctactically different languages spoken in relation with the countries of the target groups. we used our method on two models available open-source that are likely to be deployed by industry, and on two tasks and domains. we first assess the bias of a multilingual sentiment analysis model trained over multiple-languages tweets and available open-source, and then a multilingual stance recognition model trained over several languages and assessed over english language. finally we propose to link the perplexity of each example with the bias of the model, by looking at the change in label distribution with respect to the language of the target group. our work offers a fine-grained analysis of the interactions between names and languages, revealing significant biases in multilingual models.","['lrec-2024', 'coling-2024']",2024.lrec-main.134.pdf
121,238,cam 2.0: end-to-end open domain comparative question answering system,2024,"comparative question answering (compqa) is a natural language processing task that combines question answering and argument mining approaches to answer subjective comparative questions in an efficient argumentative manner. in this paper, we present an end-to-end (full pipeline) system for answering comparative questions called cam 2.0 as well as a public leaderboard called compuge that unifies the existing datasets under a single easy-to-use evaluation suite. as compared to previous web-form-based compqa systems, it features question identification, object and aspect labeling, stance classification, and summarization using up-to-date models. we also select the most time- and memory-effective pipeline by comparing separately fine-tuned transformer encoder models which show state-of-the-art performance on the subtasks with generative llms in few-shot and lora setups. we also conduct a user study for a whole-system evaluation.","['lrec-2024', 'coling-2024']",2024.lrec-main.238.pdf
122,253,can we identify stance without target arguments? a study for rumour stance classification,2024,"considering a conversation thread, rumour stance classification aims to identify the opinion (e.g. agree or disagree) of replies towards a target (rumour story). although the target is expected to be an essential component in traditional stance classification, we show that rumour stance classification datasets contain a considerable amount of real-world data whose stance could be naturally inferred directly from the replies, contributing to the strong performance of the supervised models without awareness of the target. we find that current target-aware models underperform in cases where the context of the target is crucial. finally, we propose a simple yet effective framework to enhance reasoning with the targets, achieving state-of-the-art performance on two benchmark datasets.","['lrec-2024', 'coling-2024']",2024.lrec-main.253.pdf
123,340,contextualizing generated citation texts,2024,"abstractive citation text generation is usually framed as an infilling task, where a sequence-to-sequence model is trained to generate a citation given a reference paper and the context window around the target; the generated citation should be a brief discussion of the reference paper as it relates to the citing context. however, examining a recent led-based citation generation system, we find that many of the generated citations are generic summaries of the reference paper’s main contribution, ignoring the citation context’s focus on a different topic. to address this problem, we propose a simple modification to the citation text generation task: the generation target is not only the citation itself, but the entire context window, including the target citation. this approach can be easily applied to any abstractive citation generation system, and our experimental results show that training in this way is preferred by human readers and allows the generation model to make use of contextual clues about what topic to discuss and what stance to take.","['lrec-2024', 'coling-2024']",2024.lrec-main.340.pdf
124,405,deem: dynamic experienced expert modeling for stance detection,2024,"recent work has made a preliminary attempt to use large language models (llms) to solve the stance detection task, showing promising results. however, considering that stance detection usually requires detailed background knowledge, the vanilla reasoning method may neglect the domain knowledge to make a professional and accurate analysis. thus, there is still room for improvement of llms reasoning, especially in leveraging the generation capability of llms to simulate specific experts (i.e., multi-agents) to detect the stance. in this paper, different from existing multi-agent works that require detailed descriptions and use fixed experts, we propose a dynamic experienced expert modeling (deem) method which can leverage the generated experienced experts and let llms reason in a semi-parametric way, making the experts more generalizable and reliable. experimental results demonstrate that deem consistently achieves the best results on three standard benchmarks, outperforms methods with self-consistency reasoning, and reduces the bias of llms.","['lrec-2024', 'coling-2024']",2024.lrec-main.405.pdf
125,485,"ecoverse: an annotated twitter dataset for eco-relevance classification, environmental impact analysis, and stance detection",2024,"anthropogenic ecological crisis constitutes a significant challenge that all within the academy must urgently face, including the natural language processing (nlp) community. while recent years have seen increasing work revolving around climate-centric discourse, crucial environmental and ecological topics outside of climate change remain largely unaddressed, despite their prominent importance. mainstream nlp tasks, such as sentiment analysis, dominate the scene, but there remains an untouched space in the literature involving the analysis of environmental impacts of certain events and practices. to address this gap, this paper presents ecoverse, an annotated english twitter dataset of 3,023 tweets spanning a wide spectrum of environmental topics. we propose a three-level annotation scheme designed for eco-relevance classification, stance detection, and introducing an original approach for environmental impact analysis. we detail the data collection, filtering, and labeling process that led to the creation of the dataset. remarkable inter-annotator agreement indicates that the annotation scheme produces consistent annotations of high quality. subsequent classification experiments using bert-based models, including climatebert, are presented. these yield encouraging results, while also indicating room for a model specifically tailored for environmental texts. the dataset is made freely available to stimulate further research.","['lrec-2024', 'coling-2024']",2024.lrec-main.485.pdf
126,487,edda: an encoder-decoder data augmentation framework for zero-shot stance detection,2024,"stance detection aims to determine the attitude expressed in text towards a given target. zero-shot stance detection (zssd) has emerged to classify stances towards unseen targets during inference. recent data augmentation techniques for zssd increase transferable knowledge between targets through text or target augmentation. however, these methods exhibit limitations. target augmentation lacks logical connections between generated targets and source text, while text augmentation relies solely on training data, resulting in insufficient generalization. to address these issues, we propose an encoder-decoder data augmentation (edda) framework. the encoder leverages large language models and chain-of-thought prompting to summarize texts into target-specific if-then rationales, establishing logical relationships. the decoder generates new samples based on these expressions using a semantic correlation word replacement strategy to increase syntactic diversity. we also analyze the generated expressions to develop a rationale-enhanced network that fully utilizes the augmented data. experiments on benchmark datasets demonstrate our approach substantially improves over state-of-the-art zssd techniques. the proposed edda framework increases semantic relevance and syntactic variety in augmented texts while enabling interpretable rationale-based learning.","['lrec-2024', 'coling-2024']",2024.lrec-main.487.pdf
127,594,examining temporalities on stance detection towards covid-19 vaccination,2024,"previous studies have highlighted the importance of vaccination as an effective strategy to control the transmission of the covid-19 virus. it is crucial for policymakers to have a comprehensive understanding of the public’s stance towards vaccination on a large scale. however, attitudes towards covid-19 vaccination, such as pro-vaccine or vaccine hesitancy, have evolved over time on social media. thus, it is necessary to account for possible temporal shifts when analysing these stances. this study aims to examine the impact of temporal concept drift on stance detection towards covid-19 vaccination on twitter. to this end, we evaluate a range of transformer-based models using chronological (splitting the training, validation, and test sets in order of time) and random splits (randomly splitting these three sets) of social media data. our findings reveal significant discrepancies in model performance between random and chronological splits in several existing covid-19-related datasets; specifically, chronological splits significantly reduce the accuracy of stance classification. therefore, real-world stance detection approaches need to be further refined to incorporate temporal factors as a key consideration.","['lrec-2024', 'coling-2024']",2024.lrec-main.594.pdf
128,794,inffeed: influence functions as a feedback to improve the performance of subjective tasks,2024,"recently, influence functions present an apparatus for achieving explainability for deep neural models by quantifying the perturbation of individual train instances that might impact a test prediction. our objectives in this paper are twofold. first we incorporate influence functions as a feedback into the model to improve its performance. second, in a dataset extension exercise, using influence functions to automatically identify data points that have been initially ‘silver’ annotated by some existing method and need to be cross-checked (and corrected) by annotators to improve the model performance. to meet these objectives, in this paper, we introduce inffeed, which uses influence functions to compute the influential instances for a target instance. toward the first objective, we adjust the label of the target instance based on its influencer(s) label. in doing this, inffeed outperforms the state-of-the-art baselines (including llms) by a maximum macro f1-score margin of almost 4% for hate speech classification, 3.5% for stance classification, and 3% for irony and 2% for sarcasm detection. toward the second objective we show that manually re-annotating only those silver annotated data points in the extension set that have a negative influence can immensely improve the model performance bringing it very close to the scenario where all the data points in the extension set have gold labels. this allows for huge reduction of the number of data points that need to be manually annotated since out of the silver annotated extension dataset, the influence function scheme picks up ~1/1000 points that need manual correction.","['lrec-2024', 'coling-2024']",2024.lrec-main.794.pdf
129,809,investigating the robustness of modelling decisions for few-shot cross-topic stance detection: a preregistered study,2024,"for a viewpoint-diverse news recommender, identifying whether two news articles express the same viewpoint is essential. one way to determine “same or different” viewpoint is stance detection. in this paper, we investigate the robustness of operationalization choices for few-shot stance detection, with special attention to modelling stance across different topics. our experiments test pre-registered hypotheses on stance detection. specifically, we compare two stance task definitions (pro/con versus same side stance), two llm architectures (bi-encoding versus cross-encoding), and adding natural language inference knowledge, with pre-trained roberta models trained with shots of 100 examples from 7 different stance detection datasets. some of our hypotheses and claims from earlier work can be confirmed, while others give more inconsistent results. the effect of the same side stance definition on performance differs per dataset and is influenced by other modelling choices. we found no relationship between the number of training topics in the training shots and performance. in general, cross-encoding out-performs bi-encoding, and adding nli training to our models gives considerable improvement, but these results are not consistent across all datasets. our results indicate that it is essential to include multiple datasets and systematic modelling experiments when aiming to find robust modelling choices for the concept ‘stance’.","['lrec-2024', 'coling-2024']",2024.lrec-main.809.pdf
130,871,kpatch: knowledge patch to pre-trained language model for zero-shot stance detection on social media,2024,"zero-shot stance detection on social media (zssd-sm) aims to distinguish the attitude in tweets towards an unseen target. previous work capture latent variables between source and target domains to perform this task, but the lack of context knowledge hinders the detection performance. recent studies have been devoted to obtaining the accurate representation of tweets by bringing additional facts from knowledge graph (kg), showing promising performance. however, these knowledge injection methods still suffer from two challenges: (i) the pipeline of knowledge injection causes error accumulation and (ii) irrelevant knowledge makes them fail to understand the semantics. in this paper, we propose a novel knowledge injection method for zssd-sm, which adopts two training stages, namely knowledge compression and task guidance, to flexibly inject knowledge into the pre-trained language model (plm) and adaptively expand tweets context. specifically, in the knowledge compression stage, the latent representation of kg is reconstructed by the triplet denoising task and compressed into external matrices; while in the task guidance stage, the frozen matrices are employed to guide the plm to adaptively extract its own context-related knowledge, and then complete the fine-tuning of the zssd-sm task. extensive experiments on multiple datasets show the effectiveness of our proposed method. the code is available at: https://github.com/shuohaolin/kpatch.","['lrec-2024', 'coling-2024']",2024.lrec-main.871.pdf
131,964,marasta: a multi-dialectal arabic cross-domain stance corpus,2024,"this paper introduces a cross-domain and multi-dialectal stance corpus for arabic that includes four regions in the arab world and covers the main arabic dialect groups. our corpus consists of 4657 sentences manually annotated with each sentence’s stance towards a specific topic. for each region, we collected sentences related to two controversial topics. we annotated each sentence by at least two annotators to indicate if its stance favors the topic, is against it, or is neutral. our corpus is well-balanced concerning dialect and stance. approximately half of the sentences are in modern standard arabic (msa) for each region, and the other half is in the region’s respective dialect. we conducted several machine-learning experiments for stance detection using our new corpus. our most successful model is the multi-layer perceptron (mlp), using unigram or tf-idf extracted features, which yielded an f1-score of 0.66 and an accuracy score of 0.66. compared with the most similar state-of-the-art dataset, our dataset outperformed in specific stance classes, particularly “neutral” and “against”.","['lrec-2024', 'coling-2024']",2024.lrec-main.964.pdf
132,1176,queereotypes: a multi-source italian corpus of stereotypes towards lgbtqia+ community members,2024,"the paper describes a dataset composed of two sub-corpora from two different sources in italian. the queereotypes corpus includes social media texts regarding lgbtqia+ individuals, behaviors, ideology and events. the texts were collected from facebook and twitter in 2018 and were annotated for the presence of stereotypes, and orthogonal dimensions (such as hate speech, aggressiveness, offensiveness, and irony in one sub-corpus, and stance in the other). the resource was developed by natural language processing researchers together with activists from an italian lgbtqia+ not-for-profit organization. the creation of the dataset allows the nlp community to study stereotypes against marginalized groups, individuals and, ultimately, to develop proper tools and measures to reduce the online spread of such stereotypes. a test for the robustness of the language resource has been performed by means of 5-fold cross-validation experiments. finally, text classification experiments have been carried out with a fine-tuned version of alberto (a bert-based model pre-trained on italian tweets) and mbert, obtaining good results on the task of stereotype detection, suggesting that stereotypes towards different targets might share common traits.","['lrec-2024', 'coling-2024']",2024.lrec-main.1176.pdf
133,1326,stance reasoner: zero-shot stance detection on social media with explicit reasoning,2024,"social media platforms are rich sources of opinionated content. stance detection allows the automatic extraction of users’ opinions on various topics from such content. we focus on zero-shot stance detection, where the model’s success relies on (a) having knowledge about the target topic; and (b) learning general reasoning strategies that can be employed for new topics. we present stance reasoner, an approach to zero-shot stance detection on social media that leverages explicit reasoning over background knowledge to guide the model’s inference about the document’s stance on a target. specifically, our method uses a pre-trained language model as a source of world knowledge, with the chain-of-thought in-context learning approach to generate intermediate reasoning steps. stance reasoner outperforms the current state-of-the-art models on 3 twitter datasets, including fully supervised models. it can better generalize across targets, while at the same time providing explicit and interpretable explanations for its predictions.","['lrec-2024', 'coling-2024']",2024.lrec-main.1326.pdf
134,1327,stentconv: predicting disagreement between reddit users with stance detection and a signed graph convolutional network,2024,"the rise of social media platforms has led to an increase in polarised online discussions, especially on political and socio-cultural topics such as elections and climate change. we propose a simple and entirely novel unsupervised method to better predict whether the authors of two posts agree or disagree, leveraging user stances about named entities obtained from their posts. we present stentconv, a model which builds a graph of users and named entities weighted by stance and trains a signed graph convolutional network (sgcn) to detect disagreement between comment and reply posts. we run experiments and ablation studies and show that including this information improves disagreement detection performance on a dataset of reddit posts for a range of controversial subreddit topics, without the need for platform-specific features or user history","['lrec-2024', 'coling-2024']",2024.lrec-main.1327.pdf
135,1355,target-adaptive consistency enhanced prompt-tuning for multi-domain stance detection,2024,"stance detection is a fundamental task in natural language processing (nlp). it is challenging due to diverse expressions and topics related to the targets from multiple domains. recently, prompt-tuning has been introduced to convert the original task into a cloze-style prediction task, achieving impressive results. many prompt-tuning-based methods focus on one or two classic scenarios with concrete external knowledge enhancement. however, when facing intricate information in multi-domain stance detection, these methods cannot be adaptive to multi-domain semantics. in this paper, we propose a novel target-adaptive consistency enhanced prompt-tuning method (tcp) for stance detection with multiple domains. tcp incorporates target knowledge and prior knowledge to construct target-adaptive verbalizers for diverse domains and employs pilot experiments distillation to enhance the consistency between verbalizers and model training. specifically, to capture the knowledge from multiple domains, tcp uses a target-adaptive candidate mining strategy to obtain the domain-related candidates. then, tcp refines them with prior attributes to ensure prediction consistency. the pre-trained language models (plms) in prompt-tuning are with large-scale parameters, while only changing the verbalizer without corresponding tuning has a limited impact on the training process. target-aware pilot experiments are conducted to enhance the consistency between the verbalizer and training by distilling the target-adaptive knowledge into prompt-tuning. extensive experiments and ablation studies demonstrate that tcp outperforms the state-of-the-art methods on nine stance detection datasets from multiple domains.","['lrec-2024', 'coling-2024']",2024.lrec-main.1355.pdf
136,1385,the impact of stance object type on the quality of stance detection,2024,"stance as an expression of an author’s standpoint and as a means of communication has long been studied by computational linguists. automatically identifying the stance of a subject toward an object is an active area of research in natural language processing. significant work has employed topics and claims as the object of stance, with frames of communication becoming more recently considered as alternative objects of stance. however, little attention has been paid to finding what are the benefits and what are the drawbacks when inferring the stance of a text towards different possible stance objects. in this paper we seek to answer this question by analyzing the implied knowledge and the judgments required when deciding the stance of a text towards each stance object type. our analysis informed experiments with models capable of inferring the stance of a text towards any of the stance object types considered, namely topics, claims, and frames of communication. experiments clearly indicate that it is best to infer the stance of a text towards a frame of communication, rather than a claim or a topic. it is also better to infer the stance of a text towards a claim rather than a topic. therefore we advocate that rather than continuing efforts to annotate the stance of texts towards topics, it is better to use those efforts to produce annotations towards frames of communication. these efforts will allow us to better capture the stance towards claims and topics as well.","['lrec-2024', 'coling-2024']",2024.lrec-main.1385.pdf
137,1396,the role of creaky voice in turn taking and the perception of speaker stance: experiments using controllable tts,2024,"recent advancements in spontaneous text-to-speech (tts) have enabled the realistic synthesis of creaky voice, a voice quality known for its diverse pragmatic and paralinguistic functions. in this study, we used synthesized creaky voice in perceptual tests, to explore how listeners without formal training perceive two distinct types of creaky voice. we annotated a spontaneous speech corpus using creaky voice detection tools and modified a neural tts engine with a creaky phonation embedding to control the presence of creaky phonation in the synthesized speech. we performed an objective analysis using a creak detection tool which revealed significant differences in creaky phonation levels between the two creaky voice types and modal voice. two subjective listening experiments were performed to investigate the effect of creaky voice on perceived certainty, valence, sarcasm, and turn finality. participants rated non-positional creak as less certain, less positive, and more indicative of turn finality, while positional creak was rated significantly more turn final compared to modal phonation.","['lrec-2024', 'coling-2024']",2024.lrec-main.1396.pdf
138,119,p3sum: preserving author’s perspective in news summarization with diffusion language models,2024,"in this work, we take a first step towards designing summarization systems that are faithful to the author’s intent, not only the semantic content of the article. focusing on a case study of preserving political perspectives in news summarization, we find that existing approaches alter the political opinions and stances of news articles in more than 50% of summaries, misrepresenting the intent and perspectives of the news authors. we thus propose p3sum, a diffusion model-based summarization approach controlled by political perspective classifiers. in p3sum, the political leaning of a generated summary is iteratively evaluated at each decoding step, and any drift from the article’s original stance incurs a loss back-propagated to the embedding layers, steering the political stance of the summary at inference time. extensive experiments on three news summarization datasets demonstrate that p3sum outperforms state-of-the-art summarization systems and large language models by up to 13.7% in terms of the success rate of stance preservation, with competitive performance on standard metrics of summarization quality. our findings present a first analysis of preservation of pragmatic features in summarization, highlight the lacunae in existing summarization models—that even state-of-the-art models often struggle to preserve author’s intents—and develop new summarization systems that are more faithful to author’s perspectives.",['naacl-2024'],2024.naacl-long.119.pdf
139,293,emona: event-level moral opinions in news articles,2024,"most previous research on moral frames has focused on social media short texts, little work has explored moral sentiment within news articles. in news articles, authors often express their opinions or political stance through moral judgment towards events, specifically whether the event is right or wrong according to social moral rules. this paper initiates a new task to understand moral opinions towards events in news articles. we have created a new dataset, emona, and annotated event-level moral opinions in news articles. this dataset consists of 400 news articles containing over 10k sentences and 45k events, among which 9,613 events received moral foundation labels. extracting event morality is a challenging task, as moral judgment towards events can be very implicit. baseline models were built for event moral identification and classification. in addition, we also conduct extrinsic evaluations to integrate event-level moral opinions into three downstream tasks. the statistical analysis and experiments show that moral opinions of events can serve as informative features for identifying ideological bias or subjective events.",['naacl-2024'],2024.naacl-long.293.pdf
140,32,llm-driven knowledge injection advances zero-shot and cross-target stance detection,2024,"stance detection aims at inferring an author’s attitude towards a specific target in a text. prior methods mainly consider target-related background information for a better understanding of targets while neglecting the accompanying input texts. in this study, we propose to prompt large language models (llms) to explicitly extract the relationship between paired text and target as contextual knowledge. we then inject such llm-driven knowledge into a generation model bart to exploit the rich contexts and semantics. moreover, to further enhance the decoding capability of bart, a novel prototypical contrastive scheme is designed to align input contents with stance labels. our experimental results demonstrate the state-of-the-art performance across several publicly available datasets, showcasing effectiveness in both zero-shot and cross-target stance detection scenarios. we publicly release our code to facilitate future research.",['naacl-2024'],2024.naacl-short.32.pdf
